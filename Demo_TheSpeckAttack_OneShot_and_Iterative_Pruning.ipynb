{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "BJ8MxqYz3GsA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lottery-ticket-pruner in /usr/local/lib/python3.6/dist-packages (0.8.1)\n",
      "Requirement already satisfied: numpy>=1.18.3 in /usr/local/lib/python3.6/dist-packages (from lottery-ticket-pruner) (1.19.4)\n",
      "Requirement already satisfied: keras>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from lottery-ticket-pruner) (2.4.3)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras>=2.1.0->lottery-ticket-pruner) (5.4.1)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras>=2.1.0->lottery-ticket-pruner) (2.10.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras>=2.1.0->lottery-ticket-pruner) (1.5.4)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras>=2.1.0->lottery-ticket-pruner) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.3.3)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.19.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (8.0.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install lottery-ticket-pruner\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "k3g4Wgl63dgP"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from lottery_ticket_pruner import LotteryTicketPruner\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_1Fw-MRgjau1"
   },
   "source": [
    "# The Speck cipher and data generation algorithms #\n",
    "Taken from https://github.com/agohr/deep_speck/blob/master/speck.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Vj5GsxGJ3hlH"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from os import urandom\n",
    "\n",
    "def WORD_SIZE():\n",
    "    return(16);\n",
    "\n",
    "def ALPHA():\n",
    "    return(7);\n",
    "\n",
    "def BETA():\n",
    "    return(2);\n",
    "\n",
    "MASK_VAL = 2 ** WORD_SIZE() - 1;\n",
    "\n",
    "def shuffle_together(l):\n",
    "    state = np.random.get_state();\n",
    "    for x in l:\n",
    "        np.random.set_state(state);\n",
    "        np.random.shuffle(x);\n",
    "\n",
    "def rol(x,k):\n",
    "    return(((x << k) & MASK_VAL) | (x >> (WORD_SIZE() - k)));\n",
    "\n",
    "def ror(x,k):\n",
    "    return((x >> k) | ((x << (WORD_SIZE() - k)) & MASK_VAL));\n",
    "\n",
    "def enc_one_round(p, k):\n",
    "    c0, c1 = p[0], p[1];\n",
    "    c0 = ror(c0, ALPHA());\n",
    "    c0 = (c0 + c1) & MASK_VAL;\n",
    "    c0 = c0 ^ k;\n",
    "    c1 = rol(c1, BETA());\n",
    "    c1 = c1 ^ c0;\n",
    "    return(c0,c1);\n",
    "\n",
    "def dec_one_round(c,k):\n",
    "    c0, c1 = c[0], c[1];\n",
    "    c1 = c1 ^ c0;\n",
    "    c1 = ror(c1, BETA());\n",
    "    c0 = c0 ^ k;\n",
    "    c0 = (c0 - c1) & MASK_VAL;\n",
    "    c0 = rol(c0, ALPHA());\n",
    "    return(c0, c1);\n",
    "\n",
    "def expand_key(k, t):\n",
    "    ks = [0 for i in range(t)];\n",
    "    ks[0] = k[len(k)-1];\n",
    "    l = list(reversed(k[:len(k)-1]));\n",
    "    for i in range(t-1):\n",
    "        l[i%3], ks[i+1] = enc_one_round((l[i%3], ks[i]), i);\n",
    "    return(ks);\n",
    "\n",
    "def encrypt(p, ks):\n",
    "    x, y = p[0], p[1];\n",
    "    for k in ks:\n",
    "        x,y = enc_one_round((x,y), k);\n",
    "    return(x, y);\n",
    "\n",
    "def decrypt(c, ks):\n",
    "    x, y = c[0], c[1];\n",
    "    for k in reversed(ks):\n",
    "        x, y = dec_one_round((x,y), k);\n",
    "    return(x,y);\n",
    "\n",
    "def check_testvector():\n",
    "  key = (0x1918,0x1110,0x0908,0x0100)\n",
    "  pt = (0x6574, 0x694c)\n",
    "  ks = expand_key(key, 22)\n",
    "  ct = encrypt(pt, ks)\n",
    "  if (ct == (0xa868, 0x42f2)):\n",
    "    print(\"Testvector verified.\")\n",
    "    return(True);\n",
    "  else:\n",
    "    print(\"Testvector not verified.\")\n",
    "    return(False);\n",
    "\n",
    "#convert_to_binary takes as input an array of ciphertext pairs\n",
    "#where the first row of the array contains the lefthand side of the ciphertexts,\n",
    "#the second row contains the righthand side of the ciphertexts,\n",
    "#the third row contains the lefthand side of the second ciphertexts,\n",
    "#and so on\n",
    "#it returns an array of bit vectors containing the same data\n",
    "def convert_to_binary(arr):\n",
    "  X = np.zeros((4 * WORD_SIZE(),len(arr[0])),dtype=np.uint8);\n",
    "  for i in range(4 * WORD_SIZE()):\n",
    "    index = i // WORD_SIZE();\n",
    "    offset = WORD_SIZE() - (i % WORD_SIZE()) - 1;\n",
    "    X[i] = (arr[index] >> offset) & 1;\n",
    "  X = X.transpose();\n",
    "  return(X);\n",
    "\n",
    "#takes a text file that contains encrypted block0, block1, true diff prob, real or random\n",
    "#data samples are line separated, the above items whitespace-separated\n",
    "#returns train data, ground truth, optimal ddt prediction\n",
    "def readcsv(datei):\n",
    "    data = np.genfromtxt(datei, delimiter=' ', converters={x: lambda s: int(s,16) for x in range(2)});\n",
    "    X0 = [data[i][0] for i in range(len(data))];\n",
    "    X1 = [data[i][1] for i in range(len(data))];\n",
    "    Y = [data[i][3] for i in range(len(data))];\n",
    "    Z = [data[i][2] for i in range(len(data))];\n",
    "    ct0a = [X0[i] >> 16 for i in range(len(data))];\n",
    "    ct1a = [X0[i] & MASK_VAL for i in range(len(data))];\n",
    "    ct0b = [X1[i] >> 16 for i in range(len(data))];\n",
    "    ct1b = [X1[i] & MASK_VAL for i in range(len(data))];\n",
    "    ct0a = np.array(ct0a, dtype=np.uint16); ct1a = np.array(ct1a,dtype=np.uint16);\n",
    "    ct0b = np.array(ct0b, dtype=np.uint16); ct1b = np.array(ct1b, dtype=np.uint16);\n",
    "    \n",
    "    #X = [[X0[i] >> 16, X0[i] & 0xffff, X1[i] >> 16, X1[i] & 0xffff] for i in range(len(data))];\n",
    "    X = convert_to_binary([ct0a, ct1a, ct0b, ct1b]); \n",
    "    Y = np.array(Y, dtype=np.uint8); Z = np.array(Z);\n",
    "    return(X,Y,Z);\n",
    "\n",
    "#baseline training data generator\n",
    "def make_train_data(n, nr, diff=(0x0040,0)):\n",
    "  Y = np.frombuffer(urandom(n), dtype=np.uint8); Y = Y & 1;\n",
    "  keys = np.frombuffer(urandom(8*n),dtype=np.uint16).reshape(4,-1);\n",
    "  plain0l = np.frombuffer(urandom(2*n),dtype=np.uint16);\n",
    "  plain0r = np.frombuffer(urandom(2*n),dtype=np.uint16);\n",
    "  plain1l = plain0l ^ diff[0]; plain1r = plain0r ^ diff[1];\n",
    "  num_rand_samples = np.sum(Y==0);\n",
    "  plain1l[Y==0] = np.frombuffer(urandom(2*num_rand_samples),dtype=np.uint16);\n",
    "  plain1r[Y==0] = np.frombuffer(urandom(2*num_rand_samples),dtype=np.uint16);\n",
    "  ks = expand_key(keys, nr);\n",
    "  ctdata0l, ctdata0r = encrypt((plain0l, plain0r), ks);\n",
    "  ctdata1l, ctdata1r = encrypt((plain1l, plain1r), ks);\n",
    "  X = convert_to_binary([ctdata0l, ctdata0r, ctdata1l, ctdata1r]);\n",
    "  return(X,Y);\n",
    "\n",
    "#real differences data generator\n",
    "def real_differences_data(n, nr, diff=(0x0040,0)):\n",
    "  #generate labels\n",
    "  Y = np.frombuffer(urandom(n), dtype=np.uint8); Y = Y & 1;\n",
    "  #generate keys\n",
    "  keys = np.frombuffer(urandom(8*n),dtype=np.uint16).reshape(4,-1);\n",
    "  #generate plaintexts\n",
    "  plain0l = np.frombuffer(urandom(2*n),dtype=np.uint16);\n",
    "  plain0r = np.frombuffer(urandom(2*n),dtype=np.uint16);\n",
    "  #apply input difference\n",
    "  plain1l = plain0l ^ diff[0]; plain1r = plain0r ^ diff[1];\n",
    "  num_rand_samples = np.sum(Y==0);\n",
    "  #expand keys and encrypt\n",
    "  ks = expand_key(keys, nr);\n",
    "  ctdata0l, ctdata0r = encrypt((plain0l, plain0r), ks);\n",
    "  ctdata1l, ctdata1r = encrypt((plain1l, plain1r), ks);\n",
    "  #generate blinding values\n",
    "  k0 = np.frombuffer(urandom(2*num_rand_samples),dtype=np.uint16);\n",
    "  k1 = np.frombuffer(urandom(2*num_rand_samples),dtype=np.uint16);\n",
    "  #apply blinding to the samples labelled as random\n",
    "  ctdata0l[Y==0] = ctdata0l[Y==0] ^ k0; ctdata0r[Y==0] = ctdata0r[Y==0] ^ k1;\n",
    "  ctdata1l[Y==0] = ctdata1l[Y==0] ^ k0; ctdata1r[Y==0] = ctdata1r[Y==0] ^ k1;\n",
    "  #convert to input data for neural networks\n",
    "  X = convert_to_binary([ctdata0l, ctdata0r, ctdata1l, ctdata1r]);\n",
    "  return(X,Y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kbC0HjUCkq3q"
   },
   "source": [
    "# The depth-1/10 distinguisher implementation #\n",
    "Taken from https://github.com/agohr/deep_speck/blob/master/train_nets.py and slightly adapted for running multiple trials. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "AMz2UrOU3mi8"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense, Conv1D, Input, Reshape, Permute, Add, Flatten, BatchNormalization, Activation, MaxPooling1D, Concatenate,Dropout, AveragePooling1D, GlobalAveragePooling1D, GlobalMaxPooling1D\n",
    "from keras.regularizers import l2, l1, l1_l2\n",
    "\n",
    "\n",
    "def cyclic_lr(num_epochs, high_lr, low_lr):\n",
    "  res = lambda i: low_lr + ((num_epochs-1) - i % num_epochs)/(num_epochs-1) * (high_lr - low_lr);\n",
    "  return(res);\n",
    "\n",
    "#Batch size\n",
    "bs = 5000;\n",
    "\n",
    "\n",
    "def make_resnet(num_blocks=2, num_filters=32, num_outputs=1, d1=64, d2=64, word_size=16, ks=3,depth=5, reg_param=0.0001, final_activation='sigmoid'):\n",
    "  \n",
    "  #Input and preprocessing layers\n",
    "  inp = Input(shape=(num_blocks * word_size * 2,));\n",
    "  rs = Reshape((2 * num_blocks, word_size))(inp);\n",
    "  perm = Permute((2,1))(rs);\n",
    "    \n",
    "  #Block 1\n",
    "  conv0 = Conv1D(num_filters, kernel_size=1, padding='same', kernel_regularizer=l2(reg_param))(perm);\n",
    "  conv0 = BatchNormalization()(conv0);\n",
    "  conv0 = Activation('relu')(conv0);\n",
    "    \n",
    "  #Blocks 2-i - residual blocks\n",
    "  shortcut = conv0;\n",
    "  for i in range(depth):\n",
    "    \n",
    "    conv1 = Conv1D(num_filters, kernel_size=ks, padding='same', kernel_regularizer=l2(reg_param))(shortcut);\n",
    "    conv1 = BatchNormalization()(conv1);\n",
    "    conv1 = Activation('relu')(conv1);\n",
    "    \n",
    "    conv2 = Conv1D(num_filters, kernel_size=ks, padding='same',kernel_regularizer=l2(reg_param))(conv1);\n",
    "    conv2 = BatchNormalization()(conv2);\n",
    "    conv2 = Activation('relu')(conv2);\n",
    "    shortcut = Add()([shortcut, conv2]);\n",
    "    \n",
    "  #Block 3\n",
    "  flat1 = Flatten()(shortcut);\n",
    "    \n",
    "  dense1 = Dense(d1,kernel_regularizer=l2(reg_param))(flat1);\n",
    "  dense1 = BatchNormalization()(dense1);\n",
    "  dense1 = Activation('relu')(dense1);\n",
    "\n",
    "  dense2 = Dense(d2, kernel_regularizer=l2(reg_param))(dense1);\n",
    "  dense2 = BatchNormalization()(dense2);\n",
    "  dense2 = Activation('relu')(dense2);\n",
    "    \n",
    "  out = Dense(num_outputs, activation=final_activation, kernel_regularizer=l2(reg_param))(dense2);\n",
    "\n",
    "  model = Model(inputs=inp, outputs=out);\n",
    "\n",
    "  return model\n",
    "\n",
    "\n",
    "\n",
    "def model_builder(depth):\n",
    "\n",
    "  model = make_resnet(depth=depth);\n",
    "  model.compile(\n",
    "          optimizer='adam',\n",
    "          loss='binary_crossentropy',\n",
    "          metrics=['acc']);\n",
    "  return model;\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "def train_speck_distinguisher(model, num_epochs, num_rounds, X_train, Y_train, X_eval, Y_eval):\n",
    "    \n",
    "    stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_acc', patience= 3, restore_best_weights= True);\n",
    "    lr = LearningRateScheduler(cyclic_lr(10,0.002, 0.0001));\n",
    "    \n",
    "    history = model.fit(X_train, Y_train, batch_size= bs, epochs= num_epochs, validation_data= (X_eval, Y_eval), callbacks=[lr, stop_early,])\n",
    "    best_epoch = np.argmax(history.history['val_acc']) + 1\n",
    "    \n",
    "    return(model,best_epoch);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rd7xyudBlX_6"
   },
   "source": [
    "For saving the model if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "nKSyxCZChaIw"
   },
   "outputs": [],
   "source": [
    "def save_model(model, name):\n",
    "  model_save_name = name;\n",
    "  #path = F\"/content/gdrive/My Drive/{model_save_name}\" \n",
    "  model.save(name)\n",
    "  print(\"\\n\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u2qmQ_i1liKn"
   },
   "source": [
    "# Evaluate the results #\n",
    "Taken from https://github.com/agohr/deep_speck/blob/master/eval.py and slightly adapted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "52Iifwm54h6a"
   },
   "outputs": [],
   "source": [
    "def evaluate(net,X,Y):\n",
    "    \n",
    "    Z = net.predict(X,batch_size=10000).flatten();\n",
    "    Zbin = (Z > 0.5);\n",
    "    \n",
    "    #Compute the acc, tpr, tnr\n",
    "    n = len(Z); \n",
    "    n0 = np.sum(Y==0); \n",
    "    n1 = np.sum(Y==1);\n",
    "    \n",
    "    acc = np.sum(Zbin == Y) / n;\n",
    "    tpr = np.sum(Zbin[Y==1]) / n1;\n",
    "    tnr = np.sum(Zbin[Y==0] == 0) / n0;\n",
    "    \n",
    "    return(acc, tpr, tnr); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NePJpLj0l3il"
   },
   "source": [
    "# Conduct multiple evaluations #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "oDVHt8dGFCHu"
   },
   "outputs": [],
   "source": [
    "def multiple_evaluations(model, repetitions, num_rounds):\n",
    " \n",
    "  #The accs, tprs, tnrs for all evaluation repetition\n",
    "  accs = [];\n",
    "  tprs = [];\n",
    "  tnrs = [];\n",
    "    \n",
    "  #Evaluate multiple times and average the results \n",
    "  for i in range(0, repetitions):\n",
    "    X_eval, Y_eval = make_train_data(10**6, num_rounds);\n",
    "\n",
    "    (acc, tpr, tnr) = evaluate(model, X_eval, Y_eval);\n",
    "    accs.append(acc);\n",
    "    tprs.append(tpr);\n",
    "    tnrs.append(tnr);\n",
    "\n",
    "  print(\"Acc: \" + str(np.mean(accs)) + str(\" +- \") + str(np.std(accs)) + str(\"\\t\") + \n",
    "        \"Tpr:\" + str(np.mean(tprs)) + str(\" +- \") + str(np.std(tprs)) + str(\"\\t\") +\n",
    "        \"Tnr:\" + str(np.mean(tnrs)) + str(\" +- \") + str(np.std(tnrs)) + str(\"\\t\"));\n",
    "        \n",
    "  return(np.mean(accs), np.mean(tprs), np.mean(tnrs));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a0dWTS30l-Wy"
   },
   "source": [
    "# Create a plot with values for the baseline, pruned with one-shot, and pruned with iterative model #\n",
    "The values can be Accuracy, TPR, or TNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "uKmPoVFKM3G7"
   },
   "outputs": [],
   "source": [
    "def create_figure(title, x_label, y_label, x0, y0,xy0err, x1, y1, xy1err, x2, y2, xy2err):\n",
    "    \n",
    "    fig, ax =  plt.subplots(figsize=(10,10));\n",
    "    \n",
    "    #trained baseline model \n",
    "    err= ax.errorbar(x0,y0,color = 'k', yerr=xy0err, ecolor='k', elinewidth=1, capsize=3);\n",
    "    err[-1][0].set_linestyle('--'); \n",
    "    \n",
    "    #one shot from initial\n",
    "    err=ax.errorbar(x1,y1, color ='y',yerr=xy1err, ecolor=\"y\", elinewidth=1, capsize=3);\n",
    "    err[-1][0].set_linestyle('--');\n",
    "    \n",
    "    #iterative from initial\n",
    "    err=ax.errorbar(x2,y2, color='g', yerr=xy2err, ecolor=\"g\", elinewidth=1, capsize=3);\n",
    "    err[-1][0].set_linestyle('--');\n",
    "  \n",
    "    plt.xlabel(x_label);\n",
    "    plt.ylabel(y_label);\n",
    "\n",
    "    plt.savefig(title +\".png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6WhkKhrCmBwp"
   },
   "source": [
    "# Prune a model using the one-shot or iterative pruning method for multiple values of *p%* and train it #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "x7EPQ-rSxdPC"
   },
   "outputs": [],
   "source": [
    "def apply_pruning_method(pruning_method, num_repetition, depth, num_rounds, X_train, Y_train, X_eval, Y_eval, num_epochs, num_pruning_trials, initial_baseline_model, initial_baseline_model_weights, trained_baseline_model, trained_baseline_model_weights, prune_strategy, prune_percentage_for_iterative):\n",
    "\n",
    "    #Instantiate the pruner\n",
    "    pruner = LotteryTicketPruner(initial_baseline_model);\n",
    "\n",
    "    #Store the accs, tprs, tnrs for each pruning trial (9 in total)\n",
    "    pruned_accs =[];\n",
    "    pruned_tprs = [];\n",
    "    pruned_tnrs = [];\n",
    "    \n",
    "    pruning_trial_no=0;\n",
    "    \n",
    "\n",
    "    #Conduct numtiple pruning trials (9 in total, each for a different pruning percentage)\n",
    "    for prune_percentage in list(np.linspace(start=0.1,stop=1,num=num_pruning_trials+1))[0:-1]:\n",
    "        \n",
    "        pruning_trial_no= pruning_trial_no+1;\n",
    "        \n",
    "        #Decide from what mask you want to start (new one for one-shot, previous one for iterative)\n",
    "        if pruning_method==\"one_shot\":\n",
    "          pruner.reset_masks();\n",
    "        \n",
    "        elif pruning_method==\"iterative\":\n",
    "          prune_percentage = prune_percentage_for_iterative;\n",
    "          \n",
    "        #Set the initial weights and the ones after training    \n",
    "        initial_baseline_model.set_weights(initial_baseline_model_weights);\n",
    "        trained_baseline_model.set_weights(trained_baseline_model_weights);\n",
    "\n",
    "        #Here the mask is obtained by removing prune_percentage of the trained_baseline_model's weights\n",
    "        pruner.calc_prune_mask(trained_baseline_model, prune_percentage, prune_strategy);\n",
    "        \n",
    "        #Prune the initial_baseline_model of its weights using the above-computed mask (and starting from the same initial weights)\n",
    "        pruner.apply_pruning(initial_baseline_model);\n",
    "\n",
    "        \n",
    "        #Train the above-pruned initial_baseline_model for at most the same number of epochs as the trained_baseline_model\n",
    "        (pruned_trained_model, stoped_epoch) = train_speck_distinguisher(initial_baseline_model, num_epochs, num_rounds, X_train, Y_train, X_eval, Y_eval);\n",
    "\n",
    "        print(\"Experiment repetition no:\"+ str(num_repetition)+ \" Pruned model at \" + str(prune_percentage) + \" pruning trial:\"+ str(pruning_trial_no)+\"\\n\");\n",
    "        \n",
    "        #Evaluate the pruned_trained_model\n",
    "        (acc, tpr, tnr) = multiple_evaluations(pruned_trained_model,10,num_rounds);\n",
    "\n",
    "        pruned_accs.append(acc);\n",
    "        pruned_tprs.append(tpr);\n",
    "        pruned_tnrs.append(tnr);\n",
    "\n",
    "    #Return accs, tprs, tnrs for the (9) pruning trials\n",
    "    return(pruned_accs, pruned_tprs, pruned_tnrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "12FCecJDmjSL"
   },
   "source": [
    "# Repeat:  Prune a model using the one-shot or iterative pruning method for multiple values of *p%*, train it, and evaluate the results #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "4X3G4E6sVMVT"
   },
   "outputs": [],
   "source": [
    "def repeat_experiment(num_rounds=5, num_epochs=30, num_experiment_repetitions=5, num_pruning_trials= 9, depth=10, data_for_experiment=\"Real_vs_Random\", prune_strategy=\"smallest_weights_global\", prune_percentage_for_iterative=0.2):\n",
    "    \n",
    "    \n",
    "    #Accs, tprs, tnrs for all (5) repetitions and (9) pruning trials for the baseline, pruned with one-shot and pruned with iterative models\n",
    "    baseline_accuracies_all_trials=[];\n",
    "    baseline_tprs_all_trials=[];\n",
    "    baseline_tnrs_all_trials=[];\n",
    "\n",
    "    pruned_accuracies_all_trials_one_shot_from_initial=[[] for x in range(num_pruning_trials)];\n",
    "    pruned_tprs_all_trials_one_shot_from_initial=[[] for x in range(num_pruning_trials)];\n",
    "    pruned_tnrs_all_trials_one_shot_from_initial=[[] for x in range(num_pruning_trials)];\n",
    "\n",
    "    pruned_accuracies_all_trials_iterative_from_initial=[[] for x in range(num_pruning_trials)];\n",
    "    pruned_tprs_all_trials_iterative_from_initial=[[] for x in range(num_pruning_trials)];\n",
    "    pruned_tnrs_all_trials_iterative_from_initial=[[] for x in range(num_pruning_trials)];\n",
    "\n",
    "   \n",
    "    #Repeat the experiment multiple times (5)\n",
    "    for repetition in range(0,num_experiment_repetitions):\n",
    "\n",
    "        #Compute the dataset (the real-vs-random experiment was chosen; however, the real-differences experiment can be run as well)\n",
    "        if data_for_experiment==\"Real_vs_Random\":      \n",
    "            X_train, Y_train = make_train_data(10**7,num_rounds);\n",
    "            X_eval, Y_eval = make_train_data(10**6, num_rounds);\n",
    "        elif data_for_experiment==\"Real_differences\":\n",
    "            X_train, Y_train = real_differences_data(10**7,num_rounds);\n",
    "            X_eval, Y_eval = real_differences_data(10**6, num_rounds);\n",
    "\n",
    "        #Build the initial_baseline_model and save its weights   \n",
    "        initial_baseline_model = model_builder(depth);\n",
    "        initial_baseline_model_weights = initial_baseline_model.get_weights();\n",
    "\n",
    "        #Train the initial_baseline_model and save the trained model's weights   \n",
    "        (trained_baseline_model,trnd_bm_stop_epoch) = train_speck_distinguisher(initial_baseline_model, num_epochs, num_rounds, X_train, Y_train, X_eval, Y_eval);\n",
    "        trained_baseline_model_weights = trained_baseline_model.get_weights();\n",
    "       \n",
    "        #Evaluate the trained_baseline_model \n",
    "        print(\"Baseline model results at repetition \"+str(repetition)+\":\\n\");\n",
    "        (b_acc, b_tpr, b_tnr) =multiple_evaluations(trained_baseline_model,10,num_rounds);\n",
    "        \n",
    "        #Save the trained_baseline_model's acc, tpr, tnr\n",
    "        baseline_accuracies_all_trials.append(b_acc);\n",
    "        baseline_tprs_all_trials.append(b_tpr);\n",
    "        baseline_tnrs_all_trials.append(b_tnr);\n",
    "\n",
    "        #Conduct one-shot pruning one time, for multiple pruning percentages (9 trials) \n",
    "        print(\"Starting One-Shot with initialization from original initial network:\\n\");\n",
    "        (oneShot_from_initial_pruned_accs, oneShot_from_initial_pruned_tprs, oneShot_from_initial_pruned_tnrs)=apply_pruning_method(\"one_shot\", repetition, depth, num_rounds, X_train, Y_train, X_eval, Y_eval, trnd_bm_stop_epoch, num_pruning_trials, initial_baseline_model, initial_baseline_model_weights, trained_baseline_model, trained_baseline_model_weights, prune_strategy, prune_percentage_for_iterative);\n",
    "        \n",
    "        #Conduct iterative pruning one time, for multiple pruning percentages (9 trials) \n",
    "        print(\"Starting Iterative with initialization from original initial network:\\n\");\n",
    "        (iterative_from_initial_pruned_accs, iterative_from_initial_pruned_tprs, iterative_from_initial_pruned_tnrs)=apply_pruning_method(\"iterative\", repetition, depth, num_rounds, X_train, Y_train, X_eval, Y_eval, trnd_bm_stop_epoch, num_pruning_trials, initial_baseline_model, initial_baseline_model_weights, trained_baseline_model, trained_baseline_model_weights, prune_strategy, prune_percentage_for_iterative);\n",
    "  \n",
    "        #Save the accs, tprs, tnrs from the above 2*9 pruning trials\n",
    "        for i in range(0,num_pruning_trials):\n",
    "            pruned_accuracies_all_trials_one_shot_from_initial[i].append(oneShot_from_initial_pruned_accs[i]);\n",
    "            pruned_tprs_all_trials_one_shot_from_initial[i].append(oneShot_from_initial_pruned_tprs[i]);\n",
    "            pruned_tnrs_all_trials_one_shot_from_initial[i].append(oneShot_from_initial_pruned_tnrs[i]);\n",
    "\n",
    "            pruned_accuracies_all_trials_iterative_from_initial[i].append(iterative_from_initial_pruned_accs[i]);\n",
    "            pruned_tprs_all_trials_iterative_from_initial[i].append(iterative_from_initial_pruned_tprs[i]);\n",
    "            pruned_tnrs_all_trials_iterative_from_initial[i].append(iterative_from_initial_pruned_tnrs[i]);\n",
    "\n",
    "            \n",
    "    #Return the accs, tprs, tnrs for the baseline, pruned with one-shot, pruned with iterative models.    \n",
    "    return (    baseline_accuracies_all_trials, baseline_tprs_all_trials, baseline_tnrs_all_trials,\n",
    "                pruned_accuracies_all_trials_one_shot_from_initial, pruned_tprs_all_trials_one_shot_from_initial, pruned_tnrs_all_trials_one_shot_from_initial, \n",
    "                pruned_accuracies_all_trials_iterative_from_initial, pruned_tprs_all_trials_iterative_from_initial, pruned_tnrs_all_trials_iterative_from_initial,\n",
    "           );\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uqz7c8bRnHmy"
   },
   "source": [
    "Compute pruning percentage (*p%*) values for iterative pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "VlTbq2oYVenT"
   },
   "outputs": [],
   "source": [
    "def compute_pruning_percentages_iterative(num_pruning_trials, pruning_percentage):\n",
    "  \n",
    "  remaining_weights=1;\n",
    "  percentages=[];\n",
    "\n",
    "  for i in range(0, num_pruning_trials):\n",
    "    remaining_weights= remaining_weights - remaining_weights*pruning_percentage;\n",
    "    percentages.append(1- remaining_weights);\n",
    "\n",
    "  return percentages;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O3E0VyE3nSOW"
   },
   "source": [
    "# Create the Accuracy, TPR and TNR plots #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "cLDsMtOYHQg1"
   },
   "outputs": [],
   "source": [
    "def create_plots_for_executed_experiments(experiment_type, depth, num_rounds, num_experiment_repetitions, num_pruning_trials, prune_percentage_for_iterative, b_accs, b_tprs, b_tnrs, os_init_accs, os_init_tprs, os_init_tnrs, it_init_accs, it_init_tprs, it_init_tnrs):\n",
    "        \n",
    "      #Details about the experiment  \n",
    "      print(\"Experiment type: \"+experiment_type);\n",
    "      print(\"Model depth: \"+ str(depth));\n",
    "      print(\"Speck reduced to \"+str(num_rounds) +\" R\");\n",
    "\n",
    "      #Compute pruning percentages for both experiments (9 pruning percentages)  \n",
    "      pruning_percentages_one_shot = list(np.linspace(start=0.1,stop=1,num=num_pruning_trials+1))[0:-1];\n",
    "      pruning_percentages_iterative = compute_pruning_percentages_iterative(num_pruning_trials, prune_percentage_for_iterative);\n",
    "\n",
    "      #Store the accs, tprs, tnrs per experiment repetition\n",
    "      b_accs0 =[];\n",
    "      b_accs0err=[[],[]];\n",
    "      b_tprs0 =[];\n",
    "      b_tprs0err = [[],[]];\n",
    "      b_tnrs0 = [];\n",
    "      b_tnrs0err = [[],[]]; \n",
    "        \n",
    "    \n",
    "      os_init_accs1= [];\n",
    "      os_init_accs1err= [[],[]];\n",
    "\n",
    "      os_init_tprs1= [];\n",
    "      os_init_tprs1err= [[],[]];\n",
    "\n",
    "      os_init_tnrs1= [];\n",
    "      os_init_tnrs1err= [[],[]];\n",
    "      \n",
    "\n",
    "      it_init_accs3= [];\n",
    "      it_init_accs3err= [[],[]];\n",
    "\n",
    "      it_init_tprs3= [];\n",
    "      it_init_tprs3err= [[],[]];\n",
    "\n",
    "      it_init_tnrs3= [];\n",
    "      it_init_tnrs3err= [[],[]];\n",
    "      \n",
    "      #Put the accs, tprs, tnrs and error bars in the corresponding lists for making the plots for the baseline model  \n",
    "      b_accs0 = [np.mean(b_accs)] *  num_pruning_trials;\n",
    "      b_accs0err[0] = [np.mean(b_accs)-np.min(b_accs)] * num_pruning_trials;\n",
    "      b_accs0err[1] = [np.max(b_accs) -np.mean(b_accs)] * num_pruning_trials;\n",
    "\n",
    "      b_tprs0 = [np.mean(b_tprs)] * num_pruning_trials;\n",
    "      b_tprs0err[0] = [np.mean(b_tprs)-np.min(b_tprs)]* num_pruning_trials;\n",
    "      b_tprs0err[1] = [np.max(b_tprs) -np.mean(b_tprs)]* num_pruning_trials;\n",
    "\n",
    "      b_tnrs0 = [np.mean(b_tnrs)] * num_pruning_trials;\n",
    "      b_tnrs0err[0] = [np.mean(b_tnrs)-np.min(b_tnrs)] * num_pruning_trials;\n",
    "      b_tnrs0err[1] = [np.max(b_tnrs)-np.mean(b_tnrs)] * num_pruning_trials;\n",
    "\n",
    "\n",
    "\n",
    "      #Put the accs, tprs, tnrs and error bars in the corresponding lists for making the plots for the pruned with one-shot and iterative model\n",
    "      for repetition in range(0, num_pruning_trials):\n",
    "        \n",
    "          os_init_accs1.append(np.mean(os_init_accs[repetition]));\n",
    "          os_init_accs1err[0].append(np.mean(os_init_accs[repetition])- np.min(os_init_accs[repetition]));\n",
    "          os_init_accs1err[1].append(np.max(os_init_accs[repetition]) - np.mean(os_init_accs[repetition]));\n",
    "\n",
    "          os_init_tprs1.append(np.mean(os_init_tprs[repetition]));\n",
    "          os_init_tprs1err[0].append(np.mean(os_init_tprs[repetition]) - np.min(os_init_tprs[repetition]));\n",
    "          os_init_tprs1err[1].append(np.max(os_init_tprs[repetition]) - np.mean(os_init_tprs[repetition]));\n",
    "\n",
    "          os_init_tnrs1.append(np.mean(os_init_tnrs[repetition]));\n",
    "          os_init_tnrs1err[0].append(np.mean(os_init_tnrs[repetition])- np.min(os_init_tnrs[repetition]));\n",
    "          os_init_tnrs1err[1].append(np.max(os_init_tnrs[repetition]) -np.mean(os_init_tnrs[repetition]));\n",
    "        \n",
    "\n",
    "          it_init_accs3.append(np.mean(it_init_accs[repetition]));\n",
    "          it_init_accs3err[0].append(np.mean(it_init_accs[repetition]) - np.min(it_init_accs[repetition]));\n",
    "          it_init_accs3err[1].append(np.max(it_init_accs[repetition]) - np.mean(it_init_accs[repetition]));\n",
    "\n",
    "          it_init_tprs3.append(np.mean(it_init_tprs[repetition]));\n",
    "          it_init_tprs3err[0].append(np.mean(it_init_tprs[repetition])-np.min(it_init_tprs[repetition]));\n",
    "          it_init_tprs3err[1].append(np.max(it_init_tprs[repetition]) - np.mean(it_init_tprs[repetition]));\n",
    "\n",
    "          it_init_tnrs3.append(np.mean(it_init_tnrs[repetition]));\n",
    "          it_init_tnrs3err[0].append(np.mean(it_init_tnrs[repetition])-np.min(it_init_tnrs[repetition]));\n",
    "          it_init_tnrs3err[1].append(np.max(it_init_tnrs[repetition]) - np.mean(it_init_tnrs[repetition]));\n",
    "\n",
    "\n",
    "   \n",
    "      #Create the acc, tpr, tnr figures for the baseline, pruned with one-shot and iterative models\n",
    "      create_figure(\"Accuracies-\"+\"R:\"+str(num_rounds)+\"-\"+experiment_type,\"Pruned ratio\", \"Accuracy\", pruning_percentages_one_shot, b_accs0, b_accs0err, pruning_percentages_one_shot, os_init_accs1, os_init_accs1err, pruning_percentages_iterative, it_init_accs3, it_init_accs3err);\n",
    "      create_figure(\"TPRS-\"+\"R:\"+str(num_rounds)+\"-\"+experiment_type,\"Pruned ratio\", \"TPR\", pruning_percentages_one_shot, b_tprs0, b_tprs0err, pruning_percentages_one_shot, os_init_tprs1, os_init_tprs1err, pruning_percentages_iterative, it_init_tprs3, it_init_tprs3err);\n",
    "      create_figure(\"TNRS-\"+\"R:\"+str(num_rounds) +\"-\"+experiment_type,\"Pruned ratio\", \"TNR\", pruning_percentages_one_shot, b_tnrs0, b_tnrs0err, pruning_percentages_one_shot, os_init_tnrs1, os_init_tnrs1err, pruning_percentages_iterative, it_init_tnrs3, it_init_tnrs3err);\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VLUh_AOKni9d"
   },
   "source": [
    "# Run the experiment #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "B6rq81yHruFy"
   },
   "outputs": [],
   "source": [
    "num_rounds=7; # 5, 6, 7, 8\n",
    "num_epochs=20;\n",
    "num_experiment_repetitions=3; # 5\n",
    "num_pruning_trials= 9;\n",
    "depth=1; # 1, 10\n",
    "data_for_experiment=\"Real_vs_Random\";\n",
    "experiment_type= data_for_experiment;\n",
    "prune_strategy=\"smallest_weights_global\";\n",
    "prune_percentage_for_iterative=0.2;\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "rdqzYEwsrkA2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2000/2000 [==============================] - 46s 10ms/step - loss: 0.7074 - acc: 0.5110 - val_loss: 0.6787 - val_acc: 0.5815\n",
      "Epoch 2/20\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6720 - acc: 0.5925 - val_loss: 0.6700 - val_acc: 0.5953\n",
      "Epoch 3/20\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6681 - acc: 0.5967 - val_loss: 0.6675 - val_acc: 0.5969\n",
      "Epoch 4/20\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6666 - acc: 0.5978 - val_loss: 0.6665 - val_acc: 0.5973\n",
      "Epoch 5/20\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6654 - acc: 0.5993 - val_loss: 0.6652 - val_acc: 0.5993\n",
      "Epoch 6/20\n",
      "2000/2000 [==============================] - 20s 10ms/step - loss: 0.6640 - acc: 0.6011 - val_loss: 0.6641 - val_acc: 0.6017\n",
      "Epoch 7/20\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6623 - acc: 0.6037 - val_loss: 0.6623 - val_acc: 0.6036\n",
      "Epoch 8/20\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6610 - acc: 0.6057 - val_loss: 0.6614 - val_acc: 0.6050\n",
      "Epoch 9/20\n",
      "2000/2000 [==============================] - 20s 10ms/step - loss: 0.6599 - acc: 0.6066 - val_loss: 0.6602 - val_acc: 0.6057\n",
      "Epoch 10/20\n",
      "2000/2000 [==============================] - 20s 10ms/step - loss: 0.6588 - acc: 0.6080 - val_loss: 0.6591 - val_acc: 0.6067\n",
      "Epoch 11/20\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6632 - acc: 0.6031 - val_loss: 0.6654 - val_acc: 0.6009\n",
      "Epoch 12/20\n",
      "2000/2000 [==============================] - 20s 10ms/step - loss: 0.6631 - acc: 0.6042 - val_loss: 0.6643 - val_acc: 0.6021\n",
      "Epoch 13/20\n",
      "2000/2000 [==============================] - 20s 10ms/step - loss: 0.6629 - acc: 0.6042 - val_loss: 0.6641 - val_acc: 0.6026\n",
      "Baseline model results at repetition 0:\n",
      "\n",
      "Acc: 0.6076648 +- 0.0005237922870756978\tTpr:0.546766322762257 +- 0.000642397964192116\tTnr:0.6685532006480803 +- 0.0007615720041347546\t\n",
      "Starting One-Shot with initialization from original initial network:\n",
      "\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6645 - acc: 0.6022 - val_loss: 0.6647 - val_acc: 0.6021\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6635 - acc: 0.6035 - val_loss: 0.6642 - val_acc: 0.6023\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 20s 10ms/step - loss: 0.6629 - acc: 0.6041 - val_loss: 0.6637 - val_acc: 0.6023\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 20s 10ms/step - loss: 0.6623 - acc: 0.6046 - val_loss: 0.6656 - val_acc: 0.6000\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6617 - acc: 0.6050 - val_loss: 0.6623 - val_acc: 0.6041\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 20s 10ms/step - loss: 0.6610 - acc: 0.6056 - val_loss: 0.6612 - val_acc: 0.6051\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 20s 10ms/step - loss: 0.6603 - acc: 0.6062 - val_loss: 0.6608 - val_acc: 0.6054\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 20s 10ms/step - loss: 0.6596 - acc: 0.6070 - val_loss: 0.6601 - val_acc: 0.6056\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 20s 10ms/step - loss: 0.6587 - acc: 0.6078 - val_loss: 0.6591 - val_acc: 0.6067\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6578 - acc: 0.6087 - val_loss: 0.6585 - val_acc: 0.6073\n",
      "Experiment repetition no:0 Pruned model at 0.1 pruning trial:1\n",
      "\n",
      "Acc: 0.6079560999999999 +- 0.0005960718832489999\tTpr:0.5448432197700945 +- 0.0009439093987475023\tTnr:0.671031097468932 +- 0.0006082189552250092\t\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6638 - acc: 0.6027 - val_loss: 0.6646 - val_acc: 0.6021\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 20s 10ms/step - loss: 0.6632 - acc: 0.6037 - val_loss: 0.6640 - val_acc: 0.6024\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6628 - acc: 0.6041 - val_loss: 0.6641 - val_acc: 0.6027\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6622 - acc: 0.6045 - val_loss: 0.6629 - val_acc: 0.6029\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6616 - acc: 0.6052 - val_loss: 0.6621 - val_acc: 0.6037\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6610 - acc: 0.6057 - val_loss: 0.6614 - val_acc: 0.6050\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6603 - acc: 0.6061 - val_loss: 0.6606 - val_acc: 0.6057\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 20s 10ms/step - loss: 0.6596 - acc: 0.6069 - val_loss: 0.6600 - val_acc: 0.6062\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 20s 10ms/step - loss: 0.6587 - acc: 0.6078 - val_loss: 0.6592 - val_acc: 0.6070\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6578 - acc: 0.6087 - val_loss: 0.6584 - val_acc: 0.6079\n",
      "Experiment repetition no:0 Pruned model at 0.2 pruning trial:2\n",
      "\n",
      "Acc: 0.6082554 +- 0.00047670057688238576\tTpr:0.5420616960620344 +- 0.0008284184891305481\tTnr:0.6744538011152643 +- 0.0005244275347886408\t\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6638 - acc: 0.6026 - val_loss: 0.6644 - val_acc: 0.6019\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6631 - acc: 0.6038 - val_loss: 0.6642 - val_acc: 0.6023\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6627 - acc: 0.6042 - val_loss: 0.6629 - val_acc: 0.6038\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6621 - acc: 0.6047 - val_loss: 0.6636 - val_acc: 0.6028\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6616 - acc: 0.6051 - val_loss: 0.6623 - val_acc: 0.6037\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6609 - acc: 0.6056 - val_loss: 0.6613 - val_acc: 0.6048\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6603 - acc: 0.6062 - val_loss: 0.6608 - val_acc: 0.6051\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6596 - acc: 0.6068 - val_loss: 0.6599 - val_acc: 0.6059\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 20s 10ms/step - loss: 0.6588 - acc: 0.6077 - val_loss: 0.6591 - val_acc: 0.6069\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6579 - acc: 0.6086 - val_loss: 0.6585 - val_acc: 0.6074\n",
      "Experiment repetition no:0 Pruned model at 0.30000000000000004 pruning trial:3\n",
      "\n",
      "Acc: 0.60784 +- 0.0005619176096190605\tTpr:0.547273135986197 +- 0.0007323561704872726\tTnr:0.6684187597815339 +- 0.0005212870957786366\t\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6638 - acc: 0.6026 - val_loss: 0.6651 - val_acc: 0.6006\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6631 - acc: 0.6039 - val_loss: 0.6654 - val_acc: 0.6004\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6627 - acc: 0.6041 - val_loss: 0.6640 - val_acc: 0.6025\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6622 - acc: 0.6046 - val_loss: 0.6627 - val_acc: 0.6032\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6616 - acc: 0.6051 - val_loss: 0.6618 - val_acc: 0.6045\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6610 - acc: 0.6057 - val_loss: 0.6614 - val_acc: 0.6049\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6603 - acc: 0.6062 - val_loss: 0.6606 - val_acc: 0.6053\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6596 - acc: 0.6069 - val_loss: 0.6600 - val_acc: 0.6060\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 20s 10ms/step - loss: 0.6588 - acc: 0.6076 - val_loss: 0.6592 - val_acc: 0.6069\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6579 - acc: 0.6085 - val_loss: 0.6585 - val_acc: 0.6075\n",
      "Experiment repetition no:0 Pruned model at 0.4 pruning trial:4\n",
      "\n",
      "Acc: 0.6079585000000001 +- 0.0004556457505562667\tTpr:0.5408524102206683 +- 0.0004888064942935827\tTnr:0.6750515066836027 +- 0.0005831732890332847\t\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6637 - acc: 0.6026 - val_loss: 0.6642 - val_acc: 0.6024\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6630 - acc: 0.6039 - val_loss: 0.6651 - val_acc: 0.6012\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6626 - acc: 0.6043 - val_loss: 0.6652 - val_acc: 0.6003\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6621 - acc: 0.6046 - val_loss: 0.6626 - val_acc: 0.6041\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6615 - acc: 0.6051 - val_loss: 0.6621 - val_acc: 0.6043\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6609 - acc: 0.6057 - val_loss: 0.6618 - val_acc: 0.6047\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6603 - acc: 0.6062 - val_loss: 0.6606 - val_acc: 0.6057\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6595 - acc: 0.6069 - val_loss: 0.6599 - val_acc: 0.6061\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6587 - acc: 0.6077 - val_loss: 0.6592 - val_acc: 0.6069\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6578 - acc: 0.6087 - val_loss: 0.6584 - val_acc: 0.6073\n",
      "Experiment repetition no:0 Pruned model at 0.5 pruning trial:5\n",
      "\n",
      "Acc: 0.6079885 +- 0.0003564048961504369\tTpr:0.5484986382512813 +- 0.0004610662072846968\tTnr:0.667433202481315 +- 0.0007257142867402767\t\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6638 - acc: 0.6027 - val_loss: 0.6643 - val_acc: 0.6020\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6630 - acc: 0.6038 - val_loss: 0.6645 - val_acc: 0.6014\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6626 - acc: 0.6042 - val_loss: 0.6633 - val_acc: 0.6029\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6621 - acc: 0.6047 - val_loss: 0.6626 - val_acc: 0.6034\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6615 - acc: 0.6052 - val_loss: 0.6622 - val_acc: 0.6042\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6609 - acc: 0.6058 - val_loss: 0.6615 - val_acc: 0.6045\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6603 - acc: 0.6063 - val_loss: 0.6612 - val_acc: 0.6051\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6595 - acc: 0.6070 - val_loss: 0.6599 - val_acc: 0.6058\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6587 - acc: 0.6077 - val_loss: 0.6592 - val_acc: 0.6066\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6579 - acc: 0.6086 - val_loss: 0.6585 - val_acc: 0.6075\n",
      "Experiment repetition no:0 Pruned model at 0.6 pruning trial:6\n",
      "\n",
      "Acc: 0.6077527 +- 0.00039802563987762244\tTpr:0.5428840431637407 +- 0.0003512488076816649\tTnr:0.6725956893351748 +- 0.0008155236985392085\t\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6637 - acc: 0.6026 - val_loss: 0.6647 - val_acc: 0.6011\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 20s 10ms/step - loss: 0.6631 - acc: 0.6038 - val_loss: 0.6640 - val_acc: 0.6027\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6626 - acc: 0.6043 - val_loss: 0.6630 - val_acc: 0.6035\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6621 - acc: 0.6047 - val_loss: 0.6626 - val_acc: 0.6037\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6615 - acc: 0.6052 - val_loss: 0.6619 - val_acc: 0.6045\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6609 - acc: 0.6057 - val_loss: 0.6615 - val_acc: 0.6047\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6603 - acc: 0.6062 - val_loss: 0.6605 - val_acc: 0.6057\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6596 - acc: 0.6069 - val_loss: 0.6600 - val_acc: 0.6058\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 20s 10ms/step - loss: 0.6587 - acc: 0.6077 - val_loss: 0.6592 - val_acc: 0.6069\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6579 - acc: 0.6086 - val_loss: 0.6585 - val_acc: 0.6074\n",
      "Experiment repetition no:0 Pruned model at 0.7000000000000001 pruning trial:7\n",
      "\n",
      "Acc: 0.6077499999999999 +- 0.00042688733876749483\tTpr:0.546020999377093 +- 0.0006891409178617874\tTnr:0.6695290511237472 +- 0.0007890781541071337\t\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6637 - acc: 0.6027 - val_loss: 0.6647 - val_acc: 0.6014\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6630 - acc: 0.6038 - val_loss: 0.6643 - val_acc: 0.6022\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6626 - acc: 0.6042 - val_loss: 0.6644 - val_acc: 0.6014\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6621 - acc: 0.6047 - val_loss: 0.6629 - val_acc: 0.6039\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6615 - acc: 0.6052 - val_loss: 0.6623 - val_acc: 0.6039\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6609 - acc: 0.6057 - val_loss: 0.6615 - val_acc: 0.6042\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6603 - acc: 0.6063 - val_loss: 0.6605 - val_acc: 0.6052\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6596 - acc: 0.6068 - val_loss: 0.6600 - val_acc: 0.6061\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6588 - acc: 0.6075 - val_loss: 0.6591 - val_acc: 0.6069\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6579 - acc: 0.6086 - val_loss: 0.6585 - val_acc: 0.6076\n",
      "Experiment repetition no:0 Pruned model at 0.8 pruning trial:8\n",
      "\n",
      "Acc: 0.607843 +- 0.00041163819064805705\tTpr:0.5422423282018268 +- 0.0005795108136139993\tTnr:0.6734585880951923 +- 0.0007754290000705858\t\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6638 - acc: 0.6026 - val_loss: 0.6646 - val_acc: 0.6013\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6631 - acc: 0.6038 - val_loss: 0.6639 - val_acc: 0.6025\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 20s 10ms/step - loss: 0.6627 - acc: 0.6041 - val_loss: 0.6633 - val_acc: 0.6027\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 20s 10ms/step - loss: 0.6621 - acc: 0.6048 - val_loss: 0.6629 - val_acc: 0.6035\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6615 - acc: 0.6052 - val_loss: 0.6621 - val_acc: 0.6046\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6609 - acc: 0.6056 - val_loss: 0.6613 - val_acc: 0.6049\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6603 - acc: 0.6061 - val_loss: 0.6608 - val_acc: 0.6055\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6596 - acc: 0.6069 - val_loss: 0.6602 - val_acc: 0.6057\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 20s 10ms/step - loss: 0.6588 - acc: 0.6076 - val_loss: 0.6591 - val_acc: 0.6068\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6579 - acc: 0.6085 - val_loss: 0.6585 - val_acc: 0.6075\n",
      "Experiment repetition no:0 Pruned model at 0.9 pruning trial:9\n",
      "\n",
      "Acc: 0.6080901000000001 +- 0.0003198610479567587\tTpr:0.5389638505106598 +- 0.0004179054591597738\tTnr:0.6772016212034596 +- 0.000760366299441761\t\n",
      "Starting Iterative with initialization from original initial network:\n",
      "\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6638 - acc: 0.6026 - val_loss: 0.6640 - val_acc: 0.6022\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6630 - acc: 0.6038 - val_loss: 0.6638 - val_acc: 0.6028\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6626 - acc: 0.6042 - val_loss: 0.6641 - val_acc: 0.6023\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6621 - acc: 0.6046 - val_loss: 0.6637 - val_acc: 0.6024\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6615 - acc: 0.6052 - val_loss: 0.6622 - val_acc: 0.6040\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6609 - acc: 0.6056 - val_loss: 0.6616 - val_acc: 0.6041\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6603 - acc: 0.6062 - val_loss: 0.6610 - val_acc: 0.6051\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6595 - acc: 0.6067 - val_loss: 0.6604 - val_acc: 0.6051\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6587 - acc: 0.6075 - val_loss: 0.6594 - val_acc: 0.6063\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6579 - acc: 0.6084 - val_loss: 0.6585 - val_acc: 0.6070\n",
      "Experiment repetition no:0 Pruned model at 0.2 pruning trial:1\n",
      "\n",
      "Acc: 0.6080221 +- 0.00045889834386276287\tTpr:0.5430061471402756 +- 0.0006940588824916502\tTnr:0.6730052959518007 +- 0.00034149791236226404\t\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6638 - acc: 0.6026 - val_loss: 0.6644 - val_acc: 0.6018\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 20s 10ms/step - loss: 0.6631 - acc: 0.6037 - val_loss: 0.6642 - val_acc: 0.6015\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6626 - acc: 0.6042 - val_loss: 0.6639 - val_acc: 0.6021\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6621 - acc: 0.6046 - val_loss: 0.6627 - val_acc: 0.6035\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6615 - acc: 0.6051 - val_loss: 0.6620 - val_acc: 0.6043\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6609 - acc: 0.6056 - val_loss: 0.6616 - val_acc: 0.6043\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6603 - acc: 0.6062 - val_loss: 0.6610 - val_acc: 0.6050\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6596 - acc: 0.6068 - val_loss: 0.6600 - val_acc: 0.6058\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6588 - acc: 0.6075 - val_loss: 0.6591 - val_acc: 0.6069\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6579 - acc: 0.6085 - val_loss: 0.6585 - val_acc: 0.6075\n",
      "Experiment repetition no:0 Pruned model at 0.2 pruning trial:2\n",
      "\n",
      "Acc: 0.6078407 +- 0.000549066853852985\tTpr:0.545892069534103 +- 0.0007764050771843497\tTnr:0.6697161659770324 +- 0.0006176307598950931\t\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6638 - acc: 0.6025 - val_loss: 0.6649 - val_acc: 0.6006\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6630 - acc: 0.6037 - val_loss: 0.6642 - val_acc: 0.6018\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6626 - acc: 0.6043 - val_loss: 0.6636 - val_acc: 0.6023\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6621 - acc: 0.6047 - val_loss: 0.6628 - val_acc: 0.6033\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6615 - acc: 0.6052 - val_loss: 0.6624 - val_acc: 0.6038\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6610 - acc: 0.6054 - val_loss: 0.6619 - val_acc: 0.6039\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6603 - acc: 0.6061 - val_loss: 0.6611 - val_acc: 0.6045\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6596 - acc: 0.6068 - val_loss: 0.6600 - val_acc: 0.6058\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6588 - acc: 0.6075 - val_loss: 0.6594 - val_acc: 0.6063\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6580 - acc: 0.6085 - val_loss: 0.6586 - val_acc: 0.6072\n",
      "Experiment repetition no:0 Pruned model at 0.2 pruning trial:3\n",
      "\n",
      "Acc: 0.6075206 +- 0.00037434748563332096\tTpr:0.5406844647824036 +- 0.0006800891931929153\tTnr:0.6743694247680476 +- 0.0006356362523855356\t\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6637 - acc: 0.6026 - val_loss: 0.6644 - val_acc: 0.6018\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6630 - acc: 0.6039 - val_loss: 0.6645 - val_acc: 0.6018\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6626 - acc: 0.6042 - val_loss: 0.6634 - val_acc: 0.6029\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6621 - acc: 0.6048 - val_loss: 0.6629 - val_acc: 0.6033\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6615 - acc: 0.6050 - val_loss: 0.6628 - val_acc: 0.6030\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6609 - acc: 0.6057 - val_loss: 0.6617 - val_acc: 0.6047\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6603 - acc: 0.6062 - val_loss: 0.6608 - val_acc: 0.6055\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 20s 10ms/step - loss: 0.6596 - acc: 0.6068 - val_loss: 0.6599 - val_acc: 0.6063\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6588 - acc: 0.6077 - val_loss: 0.6593 - val_acc: 0.6066\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6579 - acc: 0.6086 - val_loss: 0.6585 - val_acc: 0.6073\n",
      "Experiment repetition no:0 Pruned model at 0.2 pruning trial:4\n",
      "\n",
      "Acc: 0.6075986 +- 0.0005140566505746349\tTpr:0.5416831430004124 +- 0.0006739228772649717\tTnr:0.6734838092315375 +- 0.000587786957960387\t\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6638 - acc: 0.6026 - val_loss: 0.6643 - val_acc: 0.6017\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6631 - acc: 0.6039 - val_loss: 0.6640 - val_acc: 0.6024\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6626 - acc: 0.6042 - val_loss: 0.6641 - val_acc: 0.6017\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6621 - acc: 0.6046 - val_loss: 0.6629 - val_acc: 0.6033\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 20s 10ms/step - loss: 0.6615 - acc: 0.6050 - val_loss: 0.6626 - val_acc: 0.6037\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6610 - acc: 0.6055 - val_loss: 0.6618 - val_acc: 0.6041\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6603 - acc: 0.6061 - val_loss: 0.6607 - val_acc: 0.6053\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6596 - acc: 0.6068 - val_loss: 0.6601 - val_acc: 0.6058\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6588 - acc: 0.6075 - val_loss: 0.6592 - val_acc: 0.6064\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6579 - acc: 0.6085 - val_loss: 0.6585 - val_acc: 0.6074\n",
      "Experiment repetition no:0 Pruned model at 0.2 pruning trial:5\n",
      "\n",
      "Acc: 0.6077882 +- 0.00045034981958471114\tTpr:0.5476965182618835 +- 0.0005440318545983713\tTnr:0.6678614609379924 +- 0.0006239959476587956\t\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6637 - acc: 0.6026 - val_loss: 0.6648 - val_acc: 0.6010\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6630 - acc: 0.6039 - val_loss: 0.6638 - val_acc: 0.6027\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6626 - acc: 0.6043 - val_loss: 0.6629 - val_acc: 0.6033\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6621 - acc: 0.6047 - val_loss: 0.6630 - val_acc: 0.6035\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6615 - acc: 0.6052 - val_loss: 0.6625 - val_acc: 0.6037\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6609 - acc: 0.6057 - val_loss: 0.6615 - val_acc: 0.6052\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6602 - acc: 0.6063 - val_loss: 0.6608 - val_acc: 0.6053\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6595 - acc: 0.6069 - val_loss: 0.6598 - val_acc: 0.6063\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6587 - acc: 0.6077 - val_loss: 0.6592 - val_acc: 0.6064\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6579 - acc: 0.6086 - val_loss: 0.6585 - val_acc: 0.6074\n",
      "Experiment repetition no:0 Pruned model at 0.2 pruning trial:6\n",
      "\n",
      "Acc: 0.6079212 +- 0.00027263117943477467\tTpr:0.5523523899274936 +- 0.0005876455130663658\tTnr:0.6635045316416619 +- 0.00046007743840435506\t\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6637 - acc: 0.6027 - val_loss: 0.6639 - val_acc: 0.6023\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6630 - acc: 0.6038 - val_loss: 0.6648 - val_acc: 0.6013\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6626 - acc: 0.6042 - val_loss: 0.6635 - val_acc: 0.6030\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6621 - acc: 0.6046 - val_loss: 0.6630 - val_acc: 0.6033\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6615 - acc: 0.6051 - val_loss: 0.6626 - val_acc: 0.6035\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6609 - acc: 0.6056 - val_loss: 0.6614 - val_acc: 0.6049\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6603 - acc: 0.6062 - val_loss: 0.6609 - val_acc: 0.6053\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6596 - acc: 0.6069 - val_loss: 0.6600 - val_acc: 0.6059\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6588 - acc: 0.6077 - val_loss: 0.6592 - val_acc: 0.6066\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 20s 10ms/step - loss: 0.6579 - acc: 0.6086 - val_loss: 0.6586 - val_acc: 0.6076\n",
      "Experiment repetition no:0 Pruned model at 0.2 pruning trial:7\n",
      "\n",
      "Acc: 0.6076987 +- 0.0004118011777545246\tTpr:0.5454252112071618 +- 0.00045319863533163814\tTnr:0.6699929677171123 +- 0.0005976969749366032\t\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6638 - acc: 0.6026 - val_loss: 0.6663 - val_acc: 0.6001\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6630 - acc: 0.6039 - val_loss: 0.6635 - val_acc: 0.6027\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6626 - acc: 0.6043 - val_loss: 0.6633 - val_acc: 0.6034\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6621 - acc: 0.6048 - val_loss: 0.6625 - val_acc: 0.6040\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 20s 10ms/step - loss: 0.6615 - acc: 0.6053 - val_loss: 0.6620 - val_acc: 0.6045\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6609 - acc: 0.6057 - val_loss: 0.6615 - val_acc: 0.6046\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6603 - acc: 0.6061 - val_loss: 0.6607 - val_acc: 0.6057\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6596 - acc: 0.6068 - val_loss: 0.6599 - val_acc: 0.6062\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6588 - acc: 0.6076 - val_loss: 0.6592 - val_acc: 0.6070\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 20s 10ms/step - loss: 0.6579 - acc: 0.6084 - val_loss: 0.6586 - val_acc: 0.6072\n",
      "Experiment repetition no:0 Pruned model at 0.2 pruning trial:8\n",
      "\n",
      "Acc: 0.6077178 +- 0.00040549027115333497\tTpr:0.5481482435009294 +- 0.0007195830860365463\tTnr:0.6673044648861943 +- 0.0005113913387944514\t\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6638 - acc: 0.6027 - val_loss: 0.6643 - val_acc: 0.6022\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6630 - acc: 0.6039 - val_loss: 0.6638 - val_acc: 0.6025\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6626 - acc: 0.6042 - val_loss: 0.6630 - val_acc: 0.6037\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6621 - acc: 0.6046 - val_loss: 0.6657 - val_acc: 0.5992\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6615 - acc: 0.6052 - val_loss: 0.6622 - val_acc: 0.6041\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6609 - acc: 0.6057 - val_loss: 0.6617 - val_acc: 0.6048\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6603 - acc: 0.6062 - val_loss: 0.6607 - val_acc: 0.6053\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6596 - acc: 0.6068 - val_loss: 0.6600 - val_acc: 0.6055\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6587 - acc: 0.6076 - val_loss: 0.6592 - val_acc: 0.6066\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6579 - acc: 0.6085 - val_loss: 0.6586 - val_acc: 0.6071\n",
      "Experiment repetition no:0 Pruned model at 0.2 pruning trial:9\n",
      "\n",
      "Acc: 0.6075664 +- 0.00030629828598932075\tTpr:0.539925853790391 +- 0.00043643735642959376\tTnr:0.6751301635918306 +- 0.00058935439383109\t\n",
      "Epoch 1/20\n",
      "2000/2000 [==============================] - 22s 10ms/step - loss: 0.7108 - acc: 0.5046 - val_loss: 0.6864 - val_acc: 0.5543\n",
      "Epoch 2/20\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6774 - acc: 0.5792 - val_loss: 0.6707 - val_acc: 0.5941\n",
      "Epoch 3/20\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6686 - acc: 0.5962 - val_loss: 0.6683 - val_acc: 0.5960\n",
      "Epoch 4/20\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6668 - acc: 0.5979 - val_loss: 0.6657 - val_acc: 0.5996\n",
      "Epoch 5/20\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6641 - acc: 0.6019 - val_loss: 0.6635 - val_acc: 0.6033\n",
      "Epoch 6/20\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6625 - acc: 0.6039 - val_loss: 0.6625 - val_acc: 0.6036\n",
      "Epoch 7/20\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6616 - acc: 0.6044 - val_loss: 0.6617 - val_acc: 0.6049\n",
      "Epoch 8/20\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6607 - acc: 0.6055 - val_loss: 0.6608 - val_acc: 0.6056\n",
      "Epoch 9/20\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6598 - acc: 0.6066 - val_loss: 0.6599 - val_acc: 0.6065\n",
      "Epoch 10/20\n",
      "2000/2000 [==============================] - 20s 10ms/step - loss: 0.6587 - acc: 0.6076 - val_loss: 0.6591 - val_acc: 0.6076\n",
      "Epoch 11/20\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6632 - acc: 0.6025 - val_loss: 0.6646 - val_acc: 0.6019\n",
      "Epoch 12/20\n",
      "2000/2000 [==============================] - 20s 10ms/step - loss: 0.6631 - acc: 0.6036 - val_loss: 0.6640 - val_acc: 0.6026\n",
      "Epoch 13/20\n",
      "2000/2000 [==============================] - 20s 10ms/step - loss: 0.6628 - acc: 0.6038 - val_loss: 0.6643 - val_acc: 0.6015\n",
      "Baseline model results at repetition 1:\n",
      "\n",
      "Acc: 0.6071190000000001 +- 0.00022965495857916757\tTpr:0.5434899954423154 +- 0.0006106971760288288\tTnr:0.6708184165932916 +- 0.000369909275557445\t\n",
      "Starting One-Shot with initialization from original initial network:\n",
      "\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 22s 11ms/step - loss: 0.6641 - acc: 0.6021 - val_loss: 0.6645 - val_acc: 0.6017\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 20s 10ms/step - loss: 0.6633 - acc: 0.6033 - val_loss: 0.6640 - val_acc: 0.6023\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 20s 10ms/step - loss: 0.6627 - acc: 0.6037 - val_loss: 0.6633 - val_acc: 0.6033\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6621 - acc: 0.6043 - val_loss: 0.6625 - val_acc: 0.6040\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6616 - acc: 0.6046 - val_loss: 0.6622 - val_acc: 0.6037\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6610 - acc: 0.6051 - val_loss: 0.6617 - val_acc: 0.6048\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6604 - acc: 0.6056 - val_loss: 0.6604 - val_acc: 0.6056\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6597 - acc: 0.6063 - val_loss: 0.6599 - val_acc: 0.6063\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6590 - acc: 0.6070 - val_loss: 0.6590 - val_acc: 0.6070\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6582 - acc: 0.6080 - val_loss: 0.6584 - val_acc: 0.6078\n",
      "Experiment repetition no:1 Pruned model at 0.1 pruning trial:1\n",
      "\n",
      "Acc: 0.6072800999999999 +- 0.0004145072858225834\tTpr:0.5397758456355651 +- 0.0004284533981844088\tTnr:0.6747232496961212 +- 0.0005022319938574448\t\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6634 - acc: 0.6026 - val_loss: 0.6638 - val_acc: 0.6026\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 20s 10ms/step - loss: 0.6629 - acc: 0.6035 - val_loss: 0.6628 - val_acc: 0.6039\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6626 - acc: 0.6038 - val_loss: 0.6630 - val_acc: 0.6033\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6621 - acc: 0.6041 - val_loss: 0.6625 - val_acc: 0.6041\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6615 - acc: 0.6047 - val_loss: 0.6620 - val_acc: 0.6039\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6609 - acc: 0.6052 - val_loss: 0.6611 - val_acc: 0.6055\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6603 - acc: 0.6056 - val_loss: 0.6605 - val_acc: 0.6060\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6597 - acc: 0.6063 - val_loss: 0.6599 - val_acc: 0.6065\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6590 - acc: 0.6070 - val_loss: 0.6592 - val_acc: 0.6072\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6582 - acc: 0.6080 - val_loss: 0.6584 - val_acc: 0.6079\n",
      "Experiment repetition no:1 Pruned model at 0.2 pruning trial:2\n",
      "\n",
      "Acc: 0.6074425999999999 +- 0.00037984133529671705\tTpr:0.5456222243405915 +- 0.0007821114976984218\tTnr:0.6691970696435521 +- 0.00046391541596757713\t\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6635 - acc: 0.6026 - val_loss: 0.6646 - val_acc: 0.6017\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6629 - acc: 0.6034 - val_loss: 0.6634 - val_acc: 0.6030\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6625 - acc: 0.6039 - val_loss: 0.6629 - val_acc: 0.6038\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6620 - acc: 0.6042 - val_loss: 0.6622 - val_acc: 0.6046\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6615 - acc: 0.6046 - val_loss: 0.6620 - val_acc: 0.6040\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6609 - acc: 0.6052 - val_loss: 0.6611 - val_acc: 0.6052\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6603 - acc: 0.6057 - val_loss: 0.6604 - val_acc: 0.6058\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6597 - acc: 0.6063 - val_loss: 0.6599 - val_acc: 0.6062\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6589 - acc: 0.6071 - val_loss: 0.6591 - val_acc: 0.6070\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6582 - acc: 0.6080 - val_loss: 0.6584 - val_acc: 0.6080\n",
      "Experiment repetition no:1 Pruned model at 0.30000000000000004 pruning trial:3\n",
      "\n",
      "Acc: 0.6074488 +- 0.0005843974332592457\tTpr:0.5356368442788204 +- 0.0005948682065459162\tTnr:0.6792908865795665 +- 0.0008656501143293173\t\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6635 - acc: 0.6025 - val_loss: 0.6641 - val_acc: 0.6012\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6629 - acc: 0.6035 - val_loss: 0.6640 - val_acc: 0.6030\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6625 - acc: 0.6039 - val_loss: 0.6640 - val_acc: 0.6024\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6620 - acc: 0.6043 - val_loss: 0.6625 - val_acc: 0.6041\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6615 - acc: 0.6047 - val_loss: 0.6616 - val_acc: 0.6051\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6609 - acc: 0.6053 - val_loss: 0.6609 - val_acc: 0.6056\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6603 - acc: 0.6059 - val_loss: 0.6603 - val_acc: 0.6060\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6596 - acc: 0.6064 - val_loss: 0.6596 - val_acc: 0.6065\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6589 - acc: 0.6071 - val_loss: 0.6591 - val_acc: 0.6069\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6581 - acc: 0.6080 - val_loss: 0.6583 - val_acc: 0.6083\n",
      "Experiment repetition no:1 Pruned model at 0.4 pruning trial:4\n",
      "\n",
      "Acc: 0.6074724 +- 0.0003052877986425197\tTpr:0.5444154740397293 +- 0.0006443690690421669\tTnr:0.6705566478808873 +- 0.00043430011450947047\t\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6635 - acc: 0.6025 - val_loss: 0.6643 - val_acc: 0.6017\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6629 - acc: 0.6035 - val_loss: 0.6636 - val_acc: 0.6030\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6625 - acc: 0.6039 - val_loss: 0.6634 - val_acc: 0.6029\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6620 - acc: 0.6042 - val_loss: 0.6626 - val_acc: 0.6037\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6615 - acc: 0.6048 - val_loss: 0.6616 - val_acc: 0.6045\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6609 - acc: 0.6052 - val_loss: 0.6610 - val_acc: 0.6053\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6603 - acc: 0.6056 - val_loss: 0.6605 - val_acc: 0.6059\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6597 - acc: 0.6064 - val_loss: 0.6602 - val_acc: 0.6063\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6589 - acc: 0.6070 - val_loss: 0.6591 - val_acc: 0.6071\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6582 - acc: 0.6078 - val_loss: 0.6584 - val_acc: 0.6078\n",
      "Experiment repetition no:1 Pruned model at 0.5 pruning trial:5\n",
      "\n",
      "Acc: 0.6070557000000001 +- 0.0005011231485373663\tTpr:0.5417655347232564 +- 0.0009560591888350597\tTnr:0.6724157216877568 +- 0.0005889923451572042\t\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 22s 11ms/step - loss: 0.6635 - acc: 0.6024 - val_loss: 0.6639 - val_acc: 0.6021\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6628 - acc: 0.6035 - val_loss: 0.6641 - val_acc: 0.6020\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6625 - acc: 0.6038 - val_loss: 0.6633 - val_acc: 0.6029\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6620 - acc: 0.6042 - val_loss: 0.6626 - val_acc: 0.6038\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6614 - acc: 0.6047 - val_loss: 0.6621 - val_acc: 0.6043\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6609 - acc: 0.6052 - val_loss: 0.6612 - val_acc: 0.6055\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6603 - acc: 0.6057 - val_loss: 0.6604 - val_acc: 0.6059\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6596 - acc: 0.6064 - val_loss: 0.6598 - val_acc: 0.6065\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6589 - acc: 0.6072 - val_loss: 0.6591 - val_acc: 0.6073\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6581 - acc: 0.6080 - val_loss: 0.6584 - val_acc: 0.6077\n",
      "Experiment repetition no:1 Pruned model at 0.6 pruning trial:6\n",
      "\n",
      "Acc: 0.6074447 +- 0.0005816911637630393\tTpr:0.5430859928090276 +- 0.000996722539098578\tTnr:0.6717452166529441 +- 0.0006074249468915508\t\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6635 - acc: 0.6024 - val_loss: 0.6638 - val_acc: 0.6021\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6628 - acc: 0.6035 - val_loss: 0.6637 - val_acc: 0.6025\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6625 - acc: 0.6039 - val_loss: 0.6630 - val_acc: 0.6033\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6620 - acc: 0.6043 - val_loss: 0.6622 - val_acc: 0.6042\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6615 - acc: 0.6047 - val_loss: 0.6617 - val_acc: 0.6045\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6609 - acc: 0.6052 - val_loss: 0.6610 - val_acc: 0.6057\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6603 - acc: 0.6057 - val_loss: 0.6607 - val_acc: 0.6054\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6597 - acc: 0.6064 - val_loss: 0.6598 - val_acc: 0.6064\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6589 - acc: 0.6070 - val_loss: 0.6591 - val_acc: 0.6072\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6581 - acc: 0.6080 - val_loss: 0.6584 - val_acc: 0.6078\n",
      "Experiment repetition no:1 Pruned model at 0.7000000000000001 pruning trial:7\n",
      "\n",
      "Acc: 0.6071770999999999 +- 0.00046918492090008854\tTpr:0.5484160660298647 +- 0.0005469090383723724\tTnr:0.6660162666108905 +- 0.0006704844877058\t\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 22s 11ms/step - loss: 0.6635 - acc: 0.6024 - val_loss: 0.6646 - val_acc: 0.6014\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6629 - acc: 0.6035 - val_loss: 0.6636 - val_acc: 0.6031\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6625 - acc: 0.6039 - val_loss: 0.6632 - val_acc: 0.6029\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6620 - acc: 0.6043 - val_loss: 0.6629 - val_acc: 0.6033\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6615 - acc: 0.6048 - val_loss: 0.6617 - val_acc: 0.6048\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6609 - acc: 0.6052 - val_loss: 0.6616 - val_acc: 0.6046\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6603 - acc: 0.6057 - val_loss: 0.6605 - val_acc: 0.6055\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6597 - acc: 0.6064 - val_loss: 0.6599 - val_acc: 0.6060\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6589 - acc: 0.6071 - val_loss: 0.6591 - val_acc: 0.6070\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6581 - acc: 0.6080 - val_loss: 0.6584 - val_acc: 0.6079\n",
      "Experiment repetition no:1 Pruned model at 0.8 pruning trial:8\n",
      "\n",
      "Acc: 0.6071829999999999 +- 0.0005908541275137347\tTpr:0.5382022083115034 +- 0.0006488707218624603\tTnr:0.6762258500749081 +- 0.0009007219209367912\t\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6635 - acc: 0.6025 - val_loss: 0.6639 - val_acc: 0.6028\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6629 - acc: 0.6035 - val_loss: 0.6639 - val_acc: 0.6025\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6625 - acc: 0.6039 - val_loss: 0.6632 - val_acc: 0.6033\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6620 - acc: 0.6043 - val_loss: 0.6623 - val_acc: 0.6040\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6614 - acc: 0.6047 - val_loss: 0.6617 - val_acc: 0.6048\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6609 - acc: 0.6053 - val_loss: 0.6611 - val_acc: 0.6050\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6603 - acc: 0.6058 - val_loss: 0.6605 - val_acc: 0.6059\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6596 - acc: 0.6064 - val_loss: 0.6596 - val_acc: 0.6069\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6589 - acc: 0.6071 - val_loss: 0.6590 - val_acc: 0.6076\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6581 - acc: 0.6081 - val_loss: 0.6584 - val_acc: 0.6082\n",
      "Experiment repetition no:1 Pruned model at 0.9 pruning trial:9\n",
      "\n",
      "Acc: 0.6073631 +- 0.000595680358917422\tTpr:0.5375192345100335 +- 0.000693300687143578\tTnr:0.6771608348203296 +- 0.0008987684617757602\t\n",
      "Starting Iterative with initialization from original initial network:\n",
      "\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 22s 11ms/step - loss: 0.6635 - acc: 0.6027 - val_loss: 0.6637 - val_acc: 0.6030\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6629 - acc: 0.6035 - val_loss: 0.6632 - val_acc: 0.6032\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6625 - acc: 0.6040 - val_loss: 0.6632 - val_acc: 0.6030\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6620 - acc: 0.6043 - val_loss: 0.6620 - val_acc: 0.6045\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6615 - acc: 0.6048 - val_loss: 0.6620 - val_acc: 0.6041\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6609 - acc: 0.6051 - val_loss: 0.6610 - val_acc: 0.6054\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6603 - acc: 0.6057 - val_loss: 0.6605 - val_acc: 0.6057\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6596 - acc: 0.6063 - val_loss: 0.6599 - val_acc: 0.6062\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6589 - acc: 0.6071 - val_loss: 0.6590 - val_acc: 0.6072\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6580 - acc: 0.6081 - val_loss: 0.6584 - val_acc: 0.6078\n",
      "Experiment repetition no:1 Pruned model at 0.2 pruning trial:1\n",
      "\n",
      "Acc: 0.6074953 +- 0.0003757994278867512\tTpr:0.5476823416757141 +- 0.0004611986481485508\tTnr:0.667284564720156 +- 0.00044176195950398526\t\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6635 - acc: 0.6025 - val_loss: 0.6635 - val_acc: 0.6028\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6629 - acc: 0.6034 - val_loss: 0.6637 - val_acc: 0.6025\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6625 - acc: 0.6039 - val_loss: 0.6634 - val_acc: 0.6027\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6620 - acc: 0.6044 - val_loss: 0.6623 - val_acc: 0.6045\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6615 - acc: 0.6047 - val_loss: 0.6631 - val_acc: 0.6030\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6609 - acc: 0.6053 - val_loss: 0.6611 - val_acc: 0.6053\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6603 - acc: 0.6058 - val_loss: 0.6604 - val_acc: 0.6058\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6596 - acc: 0.6065 - val_loss: 0.6595 - val_acc: 0.6068\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6589 - acc: 0.6072 - val_loss: 0.6589 - val_acc: 0.6077\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6581 - acc: 0.6080 - val_loss: 0.6583 - val_acc: 0.6083\n",
      "Experiment repetition no:1 Pruned model at 0.2 pruning trial:2\n",
      "\n",
      "Acc: 0.6072488 +- 0.00048691473586244576\tTpr:0.5435716613905299 +- 0.0006765448126109694\tTnr:0.6709659237409632 +- 0.0004520313371452963\t\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 22s 11ms/step - loss: 0.6635 - acc: 0.6025 - val_loss: 0.6634 - val_acc: 0.6036\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6629 - acc: 0.6034 - val_loss: 0.6633 - val_acc: 0.6035\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6625 - acc: 0.6040 - val_loss: 0.6645 - val_acc: 0.6020\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6621 - acc: 0.6044 - val_loss: 0.6628 - val_acc: 0.6036\n",
      "Experiment repetition no:1 Pruned model at 0.2 pruning trial:3\n",
      "\n",
      "Acc: 0.602654 +- 0.0004807537831364336\tTpr:0.5552201565799728 +- 0.0005136327842856775\tTnr:0.6501143843862044 +- 0.0009246541308231389\t\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6641 - acc: 0.6021 - val_loss: 0.6650 - val_acc: 0.6011\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6631 - acc: 0.6032 - val_loss: 0.6636 - val_acc: 0.6027\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6626 - acc: 0.6039 - val_loss: 0.6635 - val_acc: 0.6032\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6620 - acc: 0.6043 - val_loss: 0.6624 - val_acc: 0.6041\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6615 - acc: 0.6048 - val_loss: 0.6617 - val_acc: 0.6048\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6610 - acc: 0.6052 - val_loss: 0.6610 - val_acc: 0.6053\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6603 - acc: 0.6057 - val_loss: 0.6606 - val_acc: 0.6053\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6597 - acc: 0.6062 - val_loss: 0.6597 - val_acc: 0.6061\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6590 - acc: 0.6071 - val_loss: 0.6590 - val_acc: 0.6073\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6582 - acc: 0.6079 - val_loss: 0.6584 - val_acc: 0.6079\n",
      "Experiment repetition no:1 Pruned model at 0.2 pruning trial:4\n",
      "\n",
      "Acc: 0.6070042 +- 0.0006698845870745046\tTpr:0.5386505141047514 +- 0.0009223535524143607\tTnr:0.6753459114047952 +- 0.0006873978382575792\t\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6635 - acc: 0.6025 - val_loss: 0.6650 - val_acc: 0.6010\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6629 - acc: 0.6036 - val_loss: 0.6644 - val_acc: 0.6022\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 20s 10ms/step - loss: 0.6625 - acc: 0.6039 - val_loss: 0.6630 - val_acc: 0.6036\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6620 - acc: 0.6042 - val_loss: 0.6623 - val_acc: 0.6041\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6615 - acc: 0.6049 - val_loss: 0.6618 - val_acc: 0.6045\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6609 - acc: 0.6052 - val_loss: 0.6612 - val_acc: 0.6051\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6603 - acc: 0.6059 - val_loss: 0.6605 - val_acc: 0.6058\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6597 - acc: 0.6063 - val_loss: 0.6597 - val_acc: 0.6064\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6589 - acc: 0.6071 - val_loss: 0.6591 - val_acc: 0.6071\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6582 - acc: 0.6080 - val_loss: 0.6584 - val_acc: 0.6080\n",
      "Experiment repetition no:1 Pruned model at 0.2 pruning trial:5\n",
      "\n",
      "Acc: 0.6069852 +- 0.0004911498345718925\tTpr:0.5417430135594044 +- 0.0008201098977343506\tTnr:0.6722667948098658 +- 0.0008361858300818515\t\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6635 - acc: 0.6025 - val_loss: 0.6640 - val_acc: 0.6023\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 21s 11ms/step - loss: 0.6629 - acc: 0.6035 - val_loss: 0.6639 - val_acc: 0.6033\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6625 - acc: 0.6040 - val_loss: 0.6631 - val_acc: 0.6035\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6620 - acc: 0.6044 - val_loss: 0.6622 - val_acc: 0.6038\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6615 - acc: 0.6049 - val_loss: 0.6624 - val_acc: 0.6037\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6609 - acc: 0.6054 - val_loss: 0.6610 - val_acc: 0.6052\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6603 - acc: 0.6057 - val_loss: 0.6603 - val_acc: 0.6059\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6596 - acc: 0.6063 - val_loss: 0.6597 - val_acc: 0.6064\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6589 - acc: 0.6071 - val_loss: 0.6590 - val_acc: 0.6069\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6581 - acc: 0.6080 - val_loss: 0.6584 - val_acc: 0.6078\n",
      "Experiment repetition no:1 Pruned model at 0.2 pruning trial:6\n",
      "\n",
      "Acc: 0.6072106 +- 0.0004002951910777809\tTpr:0.5431490536437815 +- 0.0006014900667358693\tTnr:0.6713074140960519 +- 0.0006422910422348086\t\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6635 - acc: 0.6025 - val_loss: 0.6643 - val_acc: 0.6022\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6628 - acc: 0.6036 - val_loss: 0.6628 - val_acc: 0.6041\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6625 - acc: 0.6038 - val_loss: 0.6635 - val_acc: 0.6028\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6620 - acc: 0.6044 - val_loss: 0.6625 - val_acc: 0.6041\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6615 - acc: 0.6047 - val_loss: 0.6618 - val_acc: 0.6041\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6581 - acc: 0.6080 - val_loss: 0.6584 - val_acc: 0.6078\n",
      "Experiment repetition no:1 Pruned model at 0.2 pruning trial:7\n",
      "\n",
      "Acc: 0.6071778 +- 0.0003396035335505165\tTpr:0.5436368400929223 +- 0.0006794846040604995\tTnr:0.6707347131829108 +- 0.00040804307313828034\t\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6620 - acc: 0.6043 - val_loss: 0.6628 - val_acc: 0.6031\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6615 - acc: 0.6047 - val_loss: 0.6617 - val_acc: 0.6050\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6609 - acc: 0.6052 - val_loss: 0.6610 - val_acc: 0.6053\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6603 - acc: 0.6057 - val_loss: 0.6607 - val_acc: 0.6057\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6597 - acc: 0.6063 - val_loss: 0.6595 - val_acc: 0.6066\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6590 - acc: 0.6071 - val_loss: 0.6591 - val_acc: 0.6073\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6582 - acc: 0.6079 - val_loss: 0.6584 - val_acc: 0.6080\n",
      "Experiment repetition no:1 Pruned model at 0.2 pruning trial:8\n",
      "\n",
      "Acc: 0.6072115 +- 0.000426781267161533\tTpr:0.539191247793956 +- 0.0006939442913846668\tTnr:0.6752165059247008 +- 0.0004899978727251603\t\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6636 - acc: 0.6025 - val_loss: 0.6648 - val_acc: 0.6009\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6629 - acc: 0.6036 - val_loss: 0.6636 - val_acc: 0.6033\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6625 - acc: 0.6038 - val_loss: 0.6629 - val_acc: 0.6041\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6620 - acc: 0.6043 - val_loss: 0.6628 - val_acc: 0.6033\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6615 - acc: 0.6048 - val_loss: 0.6619 - val_acc: 0.6047\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6609 - acc: 0.6053 - val_loss: 0.6614 - val_acc: 0.6043\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6603 - acc: 0.6056 - val_loss: 0.6603 - val_acc: 0.6057\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6597 - acc: 0.6063 - val_loss: 0.6597 - val_acc: 0.6066\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6589 - acc: 0.6070 - val_loss: 0.6590 - val_acc: 0.6072\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6582 - acc: 0.6079 - val_loss: 0.6585 - val_acc: 0.6078\n",
      "Experiment repetition no:1 Pruned model at 0.2 pruning trial:9\n",
      "\n",
      "Acc: 0.6074528 +- 0.0005022186376469948\tTpr:0.5398926205383116 +- 0.0006233483906541008\tTnr:0.6749651608649387 +- 0.0005199018022036497\t\n",
      "Epoch 1/20\n",
      "2000/2000 [==============================] - 22s 10ms/step - loss: 0.7102 - acc: 0.5052 - val_loss: 0.6828 - val_acc: 0.5677\n",
      "Epoch 2/20\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6740 - acc: 0.5872 - val_loss: 0.6706 - val_acc: 0.5937\n",
      "Epoch 3/20\n",
      "2000/2000 [==============================] - 20s 10ms/step - loss: 0.6684 - acc: 0.5962 - val_loss: 0.6687 - val_acc: 0.5945\n",
      "Epoch 4/20\n",
      "2000/2000 [==============================] - 20s 10ms/step - loss: 0.6665 - acc: 0.5981 - val_loss: 0.6663 - val_acc: 0.5986\n",
      "Epoch 5/20\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6647 - acc: 0.6006 - val_loss: 0.6638 - val_acc: 0.6014\n",
      "Epoch 6/20\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6625 - acc: 0.6039 - val_loss: 0.6634 - val_acc: 0.6023\n",
      "Epoch 7/20\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6612 - acc: 0.6053 - val_loss: 0.6614 - val_acc: 0.6043\n",
      "Epoch 8/20\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6603 - acc: 0.6061 - val_loss: 0.6609 - val_acc: 0.6049\n",
      "Epoch 9/20\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6591 - acc: 0.6075 - val_loss: 0.6595 - val_acc: 0.6063\n",
      "Epoch 10/20\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6580 - acc: 0.6086 - val_loss: 0.6588 - val_acc: 0.6073\n",
      "Epoch 11/20\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6626 - acc: 0.6032 - val_loss: 0.6640 - val_acc: 0.6021\n",
      "Epoch 12/20\n",
      "2000/2000 [==============================] - 20s 10ms/step - loss: 0.6626 - acc: 0.6042 - val_loss: 0.6635 - val_acc: 0.6022\n",
      "Epoch 13/20\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6622 - acc: 0.6047 - val_loss: 0.6629 - val_acc: 0.6029\n",
      "Baseline model results at repetition 2:\n",
      "\n",
      "Acc: 0.6075919000000001 +- 0.0004960680296088343\tTpr:0.5469228438853659 +- 0.0007660146528450719\tTnr:0.6683243569700619 +- 0.00043618010469246795\t\n",
      "Starting One-Shot with initialization from original initial network:\n",
      "\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6635 - acc: 0.6030 - val_loss: 0.6643 - val_acc: 0.6018\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6627 - acc: 0.6041 - val_loss: 0.6659 - val_acc: 0.5981\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6622 - acc: 0.6046 - val_loss: 0.6629 - val_acc: 0.6033\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 20s 10ms/step - loss: 0.6616 - acc: 0.6050 - val_loss: 0.6625 - val_acc: 0.6033\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6609 - acc: 0.6057 - val_loss: 0.6616 - val_acc: 0.6045\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6603 - acc: 0.6062 - val_loss: 0.6608 - val_acc: 0.6048\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6596 - acc: 0.6068 - val_loss: 0.6604 - val_acc: 0.6056\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6589 - acc: 0.6074 - val_loss: 0.6595 - val_acc: 0.6065\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 20s 10ms/step - loss: 0.6581 - acc: 0.6083 - val_loss: 0.6587 - val_acc: 0.6069\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6572 - acc: 0.6092 - val_loss: 0.6580 - val_acc: 0.6076\n",
      "Experiment repetition no:2 Pruned model at 0.1 pruning trial:1\n",
      "\n",
      "Acc: 0.6084065 +- 0.00037054021374205215\tTpr:0.5369700135032368 +- 0.00039080597862874416\tTnr:0.6798700206598092 +- 0.0009617285302873323\t\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6629 - acc: 0.6034 - val_loss: 0.6633 - val_acc: 0.6030\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 20s 10ms/step - loss: 0.6624 - acc: 0.6044 - val_loss: 0.6647 - val_acc: 0.6012\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6620 - acc: 0.6047 - val_loss: 0.6631 - val_acc: 0.6030\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6615 - acc: 0.6053 - val_loss: 0.6625 - val_acc: 0.6034\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6609 - acc: 0.6057 - val_loss: 0.6617 - val_acc: 0.6043\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6603 - acc: 0.6064 - val_loss: 0.6611 - val_acc: 0.6044\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6596 - acc: 0.6068 - val_loss: 0.6603 - val_acc: 0.6054\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6589 - acc: 0.6076 - val_loss: 0.6594 - val_acc: 0.6064\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6581 - acc: 0.6083 - val_loss: 0.6587 - val_acc: 0.6069\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6572 - acc: 0.6093 - val_loss: 0.6581 - val_acc: 0.6077\n",
      "Experiment repetition no:2 Pruned model at 0.2 pruning trial:2\n",
      "\n",
      "Acc: 0.6083331 +- 0.0005459350602406896\tTpr:0.5396512272862597 +- 0.0007752029061265721\tTnr:0.6770795934311281 +- 0.0006431030614269346\t\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6629 - acc: 0.6034 - val_loss: 0.6637 - val_acc: 0.6019\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 20s 10ms/step - loss: 0.6624 - acc: 0.6044 - val_loss: 0.6635 - val_acc: 0.6026\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6620 - acc: 0.6047 - val_loss: 0.6631 - val_acc: 0.6031\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6615 - acc: 0.6052 - val_loss: 0.6623 - val_acc: 0.6035\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6609 - acc: 0.6058 - val_loss: 0.6613 - val_acc: 0.6049\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6603 - acc: 0.6063 - val_loss: 0.6609 - val_acc: 0.6053\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6596 - acc: 0.6068 - val_loss: 0.6603 - val_acc: 0.6053\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6589 - acc: 0.6076 - val_loss: 0.6597 - val_acc: 0.6065\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6582 - acc: 0.6083 - val_loss: 0.6587 - val_acc: 0.6069\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 20s 10ms/step - loss: 0.6573 - acc: 0.6092 - val_loss: 0.6581 - val_acc: 0.6077\n",
      "Experiment repetition no:2 Pruned model at 0.30000000000000004 pruning trial:3\n",
      "\n",
      "Acc: 0.6085341000000001 +- 0.000457384619330391\tTpr:0.5384514169172063 +- 0.0005475568454926186\tTnr:0.6785610345929474 +- 0.0005514679767645355\t\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6629 - acc: 0.6035 - val_loss: 0.6643 - val_acc: 0.6013\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6624 - acc: 0.6044 - val_loss: 0.6632 - val_acc: 0.6031\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6620 - acc: 0.6046 - val_loss: 0.6630 - val_acc: 0.6026\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6615 - acc: 0.6052 - val_loss: 0.6619 - val_acc: 0.6041\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6609 - acc: 0.6058 - val_loss: 0.6615 - val_acc: 0.6044\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6603 - acc: 0.6062 - val_loss: 0.6609 - val_acc: 0.6050\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6596 - acc: 0.6068 - val_loss: 0.6600 - val_acc: 0.6057\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6589 - acc: 0.6075 - val_loss: 0.6594 - val_acc: 0.6063\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6582 - acc: 0.6083 - val_loss: 0.6587 - val_acc: 0.6070\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6573 - acc: 0.6092 - val_loss: 0.6581 - val_acc: 0.6077\n",
      "Experiment repetition no:2 Pruned model at 0.4 pruning trial:4\n",
      "\n",
      "Acc: 0.6083626000000001 +- 0.00044726618472673736\tTpr:0.5427236439340665 +- 0.0005785167242049236\tTnr:0.6740130547749927 +- 0.0008711342622048581\t\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6629 - acc: 0.6032 - val_loss: 0.6664 - val_acc: 0.5979\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6623 - acc: 0.6042 - val_loss: 0.6638 - val_acc: 0.6020\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6620 - acc: 0.6048 - val_loss: 0.6635 - val_acc: 0.6021\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6614 - acc: 0.6052 - val_loss: 0.6621 - val_acc: 0.6039\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6609 - acc: 0.6057 - val_loss: 0.6617 - val_acc: 0.6039\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6603 - acc: 0.6063 - val_loss: 0.6611 - val_acc: 0.6050\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6597 - acc: 0.6068 - val_loss: 0.6604 - val_acc: 0.6051\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6589 - acc: 0.6074 - val_loss: 0.6595 - val_acc: 0.6061\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6582 - acc: 0.6082 - val_loss: 0.6587 - val_acc: 0.6070\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6574 - acc: 0.6091 - val_loss: 0.6582 - val_acc: 0.6074\n",
      "Experiment repetition no:2 Pruned model at 0.5 pruning trial:5\n",
      "\n",
      "Acc: 0.6081806 +- 0.0003828579893380769\tTpr:0.5390316172520477 +- 0.0006042723703454925\tTnr:0.6773670458037528 +- 0.0005075333261979244\t\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6628 - acc: 0.6036 - val_loss: 0.6642 - val_acc: 0.6014\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6623 - acc: 0.6044 - val_loss: 0.6636 - val_acc: 0.6024\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6619 - acc: 0.6047 - val_loss: 0.6624 - val_acc: 0.6038\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6614 - acc: 0.6052 - val_loss: 0.6617 - val_acc: 0.6042\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6608 - acc: 0.6058 - val_loss: 0.6614 - val_acc: 0.6042\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6602 - acc: 0.6063 - val_loss: 0.6606 - val_acc: 0.6053\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6596 - acc: 0.6069 - val_loss: 0.6602 - val_acc: 0.6053\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6589 - acc: 0.6076 - val_loss: 0.6596 - val_acc: 0.6062\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6582 - acc: 0.6082 - val_loss: 0.6587 - val_acc: 0.6069\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6574 - acc: 0.6091 - val_loss: 0.6581 - val_acc: 0.6072\n",
      "Experiment repetition no:2 Pruned model at 0.6 pruning trial:6\n",
      "\n",
      "Acc: 0.6083321999999999 +- 0.0006246592351034233\tTpr:0.5416007728833074 +- 0.0007930315442308913\tTnr:0.6750695155508898 +- 0.0009251362860197921\t\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6629 - acc: 0.6032 - val_loss: 0.6637 - val_acc: 0.6025\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6623 - acc: 0.6044 - val_loss: 0.6629 - val_acc: 0.6034\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6620 - acc: 0.6047 - val_loss: 0.6624 - val_acc: 0.6035\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 20s 10ms/step - loss: 0.6614 - acc: 0.6052 - val_loss: 0.6629 - val_acc: 0.6026\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 20s 10ms/step - loss: 0.6608 - acc: 0.6057 - val_loss: 0.6616 - val_acc: 0.6044\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 20s 10ms/step - loss: 0.6602 - acc: 0.6063 - val_loss: 0.6609 - val_acc: 0.6049\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6596 - acc: 0.6069 - val_loss: 0.6602 - val_acc: 0.6056\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6589 - acc: 0.6075 - val_loss: 0.6595 - val_acc: 0.6061\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6581 - acc: 0.6082 - val_loss: 0.6588 - val_acc: 0.6069\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6573 - acc: 0.6092 - val_loss: 0.6582 - val_acc: 0.6075\n",
      "Experiment repetition no:2 Pruned model at 0.7000000000000001 pruning trial:7\n",
      "\n",
      "Acc: 0.6081770999999999 +- 0.0004758679333596646\tTpr:0.5519221468585035 +- 0.0007593867154078152\tTnr:0.6643839860446545 +- 0.0006812664341044586\t\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6629 - acc: 0.6034 - val_loss: 0.6635 - val_acc: 0.6026\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 20s 10ms/step - loss: 0.6623 - acc: 0.6044 - val_loss: 0.6635 - val_acc: 0.6020\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6620 - acc: 0.6048 - val_loss: 0.6641 - val_acc: 0.6013\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6615 - acc: 0.6051 - val_loss: 0.6620 - val_acc: 0.6046\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6609 - acc: 0.6057 - val_loss: 0.6624 - val_acc: 0.6029\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6603 - acc: 0.6061 - val_loss: 0.6621 - val_acc: 0.6028\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6596 - acc: 0.6068 - val_loss: 0.6603 - val_acc: 0.6055\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6589 - acc: 0.6075 - val_loss: 0.6594 - val_acc: 0.6063\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6582 - acc: 0.6082 - val_loss: 0.6587 - val_acc: 0.6071\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6573 - acc: 0.6092 - val_loss: 0.6582 - val_acc: 0.6075\n",
      "Experiment repetition no:2 Pruned model at 0.8 pruning trial:8\n",
      "\n",
      "Acc: 0.6083894000000001 +- 0.000594223224049683\tTpr:0.5434805852485722 +- 0.0006531604922138867\tTnr:0.6732940617547137 +- 0.0006086215163138415\t\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6629 - acc: 0.6033 - val_loss: 0.6644 - val_acc: 0.6007\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6623 - acc: 0.6043 - val_loss: 0.6634 - val_acc: 0.6025\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6620 - acc: 0.6047 - val_loss: 0.6624 - val_acc: 0.6041\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6614 - acc: 0.6052 - val_loss: 0.6624 - val_acc: 0.6042\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6609 - acc: 0.6057 - val_loss: 0.6617 - val_acc: 0.6039\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6603 - acc: 0.6062 - val_loss: 0.6608 - val_acc: 0.6047\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6596 - acc: 0.6069 - val_loss: 0.6602 - val_acc: 0.6055\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6589 - acc: 0.6076 - val_loss: 0.6596 - val_acc: 0.6059\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6582 - acc: 0.6082 - val_loss: 0.6588 - val_acc: 0.6068\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6574 - acc: 0.6092 - val_loss: 0.6582 - val_acc: 0.6076\n",
      "Experiment repetition no:2 Pruned model at 0.9 pruning trial:9\n",
      "\n",
      "Acc: 0.6082985 +- 0.0005014306033739882\tTpr:0.5444380686176011 +- 0.000620862521272623\tTnr:0.6721445857078276 +- 0.0006093900080406263\t\n",
      "Starting Iterative with initialization from original initial network:\n",
      "\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6629 - acc: 0.6033 - val_loss: 0.6642 - val_acc: 0.6015\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6623 - acc: 0.6044 - val_loss: 0.6640 - val_acc: 0.6019\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6620 - acc: 0.6047 - val_loss: 0.6632 - val_acc: 0.6023\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6614 - acc: 0.6052 - val_loss: 0.6617 - val_acc: 0.6044\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6608 - acc: 0.6057 - val_loss: 0.6612 - val_acc: 0.6051\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6602 - acc: 0.6063 - val_loss: 0.6608 - val_acc: 0.6052\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6596 - acc: 0.6069 - val_loss: 0.6599 - val_acc: 0.6058\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6589 - acc: 0.6076 - val_loss: 0.6594 - val_acc: 0.6064\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6581 - acc: 0.6083 - val_loss: 0.6588 - val_acc: 0.6068\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6573 - acc: 0.6092 - val_loss: 0.6581 - val_acc: 0.6080\n",
      "Experiment repetition no:2 Pruned model at 0.2 pruning trial:1\n",
      "\n",
      "Acc: 0.6084361000000001 +- 0.0004996489667756858\tTpr:0.5355938067850409 +- 0.0005426317998114544\tTnr:0.6812875692780571 +- 0.0008125165510785562\t\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6629 - acc: 0.6035 - val_loss: 0.6649 - val_acc: 0.6003\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6624 - acc: 0.6043 - val_loss: 0.6638 - val_acc: 0.6018\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6620 - acc: 0.6047 - val_loss: 0.6629 - val_acc: 0.6031\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6615 - acc: 0.6052 - val_loss: 0.6623 - val_acc: 0.6036\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6609 - acc: 0.6057 - val_loss: 0.6621 - val_acc: 0.6033\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6603 - acc: 0.6063 - val_loss: 0.6618 - val_acc: 0.6037\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6596 - acc: 0.6069 - val_loss: 0.6601 - val_acc: 0.6058\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6589 - acc: 0.6075 - val_loss: 0.6597 - val_acc: 0.6061\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6582 - acc: 0.6082 - val_loss: 0.6587 - val_acc: 0.6071\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6573 - acc: 0.6091 - val_loss: 0.6581 - val_acc: 0.6078\n",
      "Experiment repetition no:2 Pruned model at 0.2 pruning trial:2\n",
      "\n",
      "Acc: 0.6082601999999999 +- 0.00042145291551965683\tTpr:0.5439803723151588 +- 0.00046986309849715287\tTnr:0.6725422912073611 +- 0.0006628310589507831\t\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6629 - acc: 0.6032 - val_loss: 0.6634 - val_acc: 0.6026\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 20s 10ms/step - loss: 0.6623 - acc: 0.6043 - val_loss: 0.6642 - val_acc: 0.6019\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6620 - acc: 0.6047 - val_loss: 0.6628 - val_acc: 0.6032\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 20s 10ms/step - loss: 0.6615 - acc: 0.6052 - val_loss: 0.6624 - val_acc: 0.6033\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6609 - acc: 0.6056 - val_loss: 0.6615 - val_acc: 0.6042\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6603 - acc: 0.6062 - val_loss: 0.6615 - val_acc: 0.6047\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6596 - acc: 0.6069 - val_loss: 0.6605 - val_acc: 0.6051\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6590 - acc: 0.6074 - val_loss: 0.6595 - val_acc: 0.6060\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6582 - acc: 0.6082 - val_loss: 0.6587 - val_acc: 0.6071\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6574 - acc: 0.6092 - val_loss: 0.6581 - val_acc: 0.6078\n",
      "Experiment repetition no:2 Pruned model at 0.2 pruning trial:3\n",
      "\n",
      "Acc: 0.608199 +- 0.0004864736375180092\tTpr:0.5427322645043555 +- 0.0008407255202619305\tTnr:0.6736584913970802 +- 0.0006158359713956765\t\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6629 - acc: 0.6033 - val_loss: 0.6640 - val_acc: 0.6009\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6623 - acc: 0.6043 - val_loss: 0.6628 - val_acc: 0.6033\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 20s 10ms/step - loss: 0.6619 - acc: 0.6047 - val_loss: 0.6623 - val_acc: 0.6038\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6614 - acc: 0.6052 - val_loss: 0.6620 - val_acc: 0.6038\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6609 - acc: 0.6057 - val_loss: 0.6648 - val_acc: 0.5992\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6603 - acc: 0.6063 - val_loss: 0.6605 - val_acc: 0.6056\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 20s 10ms/step - loss: 0.6596 - acc: 0.6069 - val_loss: 0.6603 - val_acc: 0.6047\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6589 - acc: 0.6073 - val_loss: 0.6595 - val_acc: 0.6065\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6582 - acc: 0.6081 - val_loss: 0.6588 - val_acc: 0.6069\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6574 - acc: 0.6091 - val_loss: 0.6582 - val_acc: 0.6074\n",
      "Experiment repetition no:2 Pruned model at 0.2 pruning trial:4\n",
      "\n",
      "Acc: 0.6079644999999999 +- 0.0003785401563903129\tTpr:0.5438714450354875 +- 0.0006268778093121261\tTnr:0.6720292521845659 +- 0.0007662256898680551\t\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6629 - acc: 0.6035 - val_loss: 0.6637 - val_acc: 0.6015\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6623 - acc: 0.6044 - val_loss: 0.6640 - val_acc: 0.6017\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6620 - acc: 0.6046 - val_loss: 0.6628 - val_acc: 0.6032\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6615 - acc: 0.6052 - val_loss: 0.6621 - val_acc: 0.6043\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6609 - acc: 0.6057 - val_loss: 0.6618 - val_acc: 0.6043\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6603 - acc: 0.6061 - val_loss: 0.6608 - val_acc: 0.6046\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6596 - acc: 0.6068 - val_loss: 0.6599 - val_acc: 0.6063\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6589 - acc: 0.6074 - val_loss: 0.6594 - val_acc: 0.6062\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6582 - acc: 0.6083 - val_loss: 0.6589 - val_acc: 0.6069\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6574 - acc: 0.6090 - val_loss: 0.6581 - val_acc: 0.6077\n",
      "Experiment repetition no:2 Pruned model at 0.2 pruning trial:5\n",
      "\n",
      "Acc: 0.6083364 +- 0.00042159345345961524\tTpr:0.5425882837439766 +- 0.0005068279555996092\tTnr:0.6740586056785576 +- 0.0006506826290035483\t\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6629 - acc: 0.6034 - val_loss: 0.6668 - val_acc: 0.5976\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6623 - acc: 0.6044 - val_loss: 0.6649 - val_acc: 0.6004\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6620 - acc: 0.6049 - val_loss: 0.6625 - val_acc: 0.6032\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6614 - acc: 0.6053 - val_loss: 0.6623 - val_acc: 0.6033\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6609 - acc: 0.6057 - val_loss: 0.6614 - val_acc: 0.6045\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6602 - acc: 0.6063 - val_loss: 0.6608 - val_acc: 0.6048\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6596 - acc: 0.6068 - val_loss: 0.6602 - val_acc: 0.6053\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6589 - acc: 0.6075 - val_loss: 0.6594 - val_acc: 0.6062\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6582 - acc: 0.6082 - val_loss: 0.6587 - val_acc: 0.6067\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6573 - acc: 0.6092 - val_loss: 0.6582 - val_acc: 0.6074\n",
      "Experiment repetition no:2 Pruned model at 0.2 pruning trial:6\n",
      "\n",
      "Acc: 0.6084072 +- 0.0004180717163358435\tTpr:0.5462650950720809 +- 0.0006929624100805797\tTnr:0.6705140719675383 +- 0.0004541362819644405\t\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6629 - acc: 0.6032 - val_loss: 0.6636 - val_acc: 0.6029\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6623 - acc: 0.6043 - val_loss: 0.6634 - val_acc: 0.6025\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6619 - acc: 0.6047 - val_loss: 0.6629 - val_acc: 0.6028\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6614 - acc: 0.6053 - val_loss: 0.6625 - val_acc: 0.6029\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6608 - acc: 0.6058 - val_loss: 0.6616 - val_acc: 0.6046\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6602 - acc: 0.6063 - val_loss: 0.6607 - val_acc: 0.6053\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6596 - acc: 0.6068 - val_loss: 0.6605 - val_acc: 0.6050\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6589 - acc: 0.6075 - val_loss: 0.6594 - val_acc: 0.6063\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6582 - acc: 0.6082 - val_loss: 0.6587 - val_acc: 0.6071\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 20s 10ms/step - loss: 0.6574 - acc: 0.6091 - val_loss: 0.6582 - val_acc: 0.6073\n",
      "Experiment repetition no:2 Pruned model at 0.2 pruning trial:7\n",
      "\n",
      "Acc: 0.6083558 +- 0.0005533573528923312\tTpr:0.5464597264465055 +- 0.0007326519192650685\tTnr:0.6701762094848258 +- 0.0007572056542112103\t\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6630 - acc: 0.6033 - val_loss: 0.6639 - val_acc: 0.6020\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6623 - acc: 0.6044 - val_loss: 0.6628 - val_acc: 0.6031\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6620 - acc: 0.6048 - val_loss: 0.6645 - val_acc: 0.6014\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6614 - acc: 0.6052 - val_loss: 0.6619 - val_acc: 0.6042\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6609 - acc: 0.6057 - val_loss: 0.6619 - val_acc: 0.6039\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6603 - acc: 0.6062 - val_loss: 0.6613 - val_acc: 0.6046\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6596 - acc: 0.6067 - val_loss: 0.6600 - val_acc: 0.6057\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6590 - acc: 0.6075 - val_loss: 0.6594 - val_acc: 0.6062\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6582 - acc: 0.6082 - val_loss: 0.6587 - val_acc: 0.6069\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6574 - acc: 0.6091 - val_loss: 0.6582 - val_acc: 0.6074\n",
      "Experiment repetition no:2 Pruned model at 0.2 pruning trial:8\n",
      "\n",
      "Acc: 0.6080413 +- 0.0004887154693684278\tTpr:0.5422244997582795 +- 0.0008988337538791154\tTnr:0.673901706901572 +- 0.0007258340471950822\t\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6630 - acc: 0.6032 - val_loss: 0.6635 - val_acc: 0.6025\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6623 - acc: 0.6042 - val_loss: 0.6638 - val_acc: 0.6019\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6620 - acc: 0.6048 - val_loss: 0.6635 - val_acc: 0.6023\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6614 - acc: 0.6052 - val_loss: 0.6625 - val_acc: 0.6034\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6609 - acc: 0.6057 - val_loss: 0.6619 - val_acc: 0.6036\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6603 - acc: 0.6062 - val_loss: 0.6609 - val_acc: 0.6048\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6596 - acc: 0.6068 - val_loss: 0.6602 - val_acc: 0.6057\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6589 - acc: 0.6074 - val_loss: 0.6596 - val_acc: 0.6062\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6582 - acc: 0.6082 - val_loss: 0.6587 - val_acc: 0.6070\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 21s 10ms/step - loss: 0.6574 - acc: 0.6092 - val_loss: 0.6581 - val_acc: 0.6076\n",
      "Experiment repetition no:2 Pruned model at 0.2 pruning trial:9\n",
      "\n",
      "Acc: 0.6081641999999999 +- 0.0005175310232246988\tTpr:0.5390384122192383 +- 0.0008187502403225016\tTnr:0.6772737774829685 +- 0.0010830140516039602\t\n"
     ]
    }
   ],
   "source": [
    "(   b_accs, b_tprs, b_tnrs,\n",
    "    os_init_accs, os_init_tprs, os_init_tnrs,\n",
    "    it_init_accs, it_init_tprs, it_init_tnrs) = repeat_experiment(num_rounds, num_epochs, num_experiment_repetitions, num_pruning_trials, depth,data_for_experiment,prune_strategy, prune_percentage_for_iterative);\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the plots #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "aVSVmi9yq2qj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment type: Real_vs_Random\n",
      "Model depth: 1\n",
      "Speck reduced to 7 R\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_plots_for_executed_experiments(experiment_type, depth, num_rounds, num_experiment_repetitions, num_pruning_trials, prune_percentage_for_iterative, b_accs, b_tprs, b_tnrs, os_init_accs, os_init_tprs, os_init_tnrs, it_init_accs, it_init_tprs, it_init_tnrs)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TheSpeckAttackReproduction_OneShot_and_Iterative_Pruning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
