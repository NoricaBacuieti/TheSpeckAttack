{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.4.3)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.19.4)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (5.4.1)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.5.4)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "YYrc0_7kKfpr"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense, Conv1D, Input, Reshape, Permute, Add, Flatten, BatchNormalization, Activation, MaxPooling1D, Concatenate,Dropout, AveragePooling1D, GlobalAveragePooling1D, GlobalMaxPooling1D, UpSampling1D\n",
    "from keras.regularizers import l2, l1, l1_l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yuHgGAdjqwFp"
   },
   "source": [
    "# The Speck cipher and data generation algorithms #\n",
    "Taken from https://github.com/agohr/deep_speck/blob/master/speck.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "-As2P_AK_gEW"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from os import urandom\n",
    "\n",
    "def WORD_SIZE():\n",
    "    return(16);\n",
    "\n",
    "def ALPHA():\n",
    "    return(7);\n",
    "\n",
    "def BETA():\n",
    "    return(2);\n",
    "\n",
    "MASK_VAL = 2 ** WORD_SIZE() - 1;\n",
    "\n",
    "def shuffle_together(l):\n",
    "    state = np.random.get_state();\n",
    "    for x in l:\n",
    "        np.random.set_state(state);\n",
    "        np.random.shuffle(x);\n",
    "\n",
    "def rol(x,k):\n",
    "    return(((x << k) & MASK_VAL) | (x >> (WORD_SIZE() - k)));\n",
    "\n",
    "def ror(x,k):\n",
    "    return((x >> k) | ((x << (WORD_SIZE() - k)) & MASK_VAL));\n",
    "\n",
    "def enc_one_round(p, k):\n",
    "    c0, c1 = p[0], p[1];\n",
    "    c0 = ror(c0, ALPHA());\n",
    "    c0 = (c0 + c1) & MASK_VAL;\n",
    "    c0 = c0 ^ k;\n",
    "    c1 = rol(c1, BETA());\n",
    "    c1 = c1 ^ c0;\n",
    "    return(c0,c1);\n",
    "\n",
    "def dec_one_round(c,k):\n",
    "    c0, c1 = c[0], c[1];\n",
    "    c1 = c1 ^ c0;\n",
    "    c1 = ror(c1, BETA());\n",
    "    c0 = c0 ^ k;\n",
    "    c0 = (c0 - c1) & MASK_VAL;\n",
    "    c0 = rol(c0, ALPHA());\n",
    "    return(c0, c1);\n",
    "\n",
    "def expand_key(k, t):\n",
    "    ks = [0 for i in range(t)];\n",
    "    ks[0] = k[len(k)-1];\n",
    "    l = list(reversed(k[:len(k)-1]));\n",
    "    for i in range(t-1):\n",
    "        l[i%3], ks[i+1] = enc_one_round((l[i%3], ks[i]), i);\n",
    "    return(ks);\n",
    "\n",
    "def encrypt(p, ks):\n",
    "    x, y = p[0], p[1];\n",
    "    for k in ks:\n",
    "        x,y = enc_one_round((x,y), k);\n",
    "    return(x, y);\n",
    "\n",
    "def decrypt(c, ks):\n",
    "    x, y = c[0], c[1];\n",
    "    for k in reversed(ks):\n",
    "        x, y = dec_one_round((x,y), k);\n",
    "    return(x,y);\n",
    "\n",
    "def check_testvector():\n",
    "  key = (0x1918,0x1110,0x0908,0x0100)\n",
    "  pt = (0x6574, 0x694c)\n",
    "  ks = expand_key(key, 22)\n",
    "  ct = encrypt(pt, ks)\n",
    "  if (ct == (0xa868, 0x42f2)):\n",
    "    print(\"Testvector verified.\")\n",
    "    return(True);\n",
    "  else:\n",
    "    print(\"Testvector not verified.\")\n",
    "    return(False);\n",
    "\n",
    "#convert_to_binary takes as input an array of ciphertext pairs\n",
    "#where the first row of the array contains the lefthand side of the ciphertexts,\n",
    "#the second row contains the righthand side of the ciphertexts,\n",
    "#the third row contains the lefthand side of the second ciphertexts,\n",
    "#and so on\n",
    "#it returns an array of bit vectors containing the same data\n",
    "def convert_to_binary(arr):\n",
    "  X = np.zeros((4 * WORD_SIZE(),len(arr[0])),dtype=np.uint8);\n",
    "  for i in range(4 * WORD_SIZE()):\n",
    "    index = i // WORD_SIZE();\n",
    "    offset = WORD_SIZE() - (i % WORD_SIZE()) - 1;\n",
    "    X[i] = (arr[index] >> offset) & 1;\n",
    "  X = X.transpose();\n",
    "  return(X);\n",
    "\n",
    "#takes a text file that contains encrypted block0, block1, true diff prob, real or random\n",
    "#data samples are line separated, the above items whitespace-separated\n",
    "#returns train data, ground truth, optimal ddt prediction\n",
    "def readcsv(datei):\n",
    "    data = np.genfromtxt(datei, delimiter=' ', converters={x: lambda s: int(s,16) for x in range(2)});\n",
    "    X0 = [data[i][0] for i in range(len(data))];\n",
    "    X1 = [data[i][1] for i in range(len(data))];\n",
    "    Y = [data[i][3] for i in range(len(data))];\n",
    "    Z = [data[i][2] for i in range(len(data))];\n",
    "    ct0a = [X0[i] >> 16 for i in range(len(data))];\n",
    "    ct1a = [X0[i] & MASK_VAL for i in range(len(data))];\n",
    "    ct0b = [X1[i] >> 16 for i in range(len(data))];\n",
    "    ct1b = [X1[i] & MASK_VAL for i in range(len(data))];\n",
    "    ct0a = np.array(ct0a, dtype=np.uint16); ct1a = np.array(ct1a,dtype=np.uint16);\n",
    "    ct0b = np.array(ct0b, dtype=np.uint16); ct1b = np.array(ct1b, dtype=np.uint16);\n",
    "    \n",
    "    #X = [[X0[i] >> 16, X0[i] & 0xffff, X1[i] >> 16, X1[i] & 0xffff] for i in range(len(data))];\n",
    "    X = convert_to_binary([ct0a, ct1a, ct0b, ct1b]); \n",
    "    Y = np.array(Y, dtype=np.uint8); Z = np.array(Z);\n",
    "    return(X,Y,Z);\n",
    "\n",
    "#baseline training data generator\n",
    "def make_train_data(n, nr, diff=(0x0040,0)):\n",
    "  Y = np.frombuffer(urandom(n), dtype=np.uint8); Y = Y & 1;\n",
    "  keys = np.frombuffer(urandom(8*n),dtype=np.uint16).reshape(4,-1);\n",
    "  plain0l = np.frombuffer(urandom(2*n),dtype=np.uint16);\n",
    "  plain0r = np.frombuffer(urandom(2*n),dtype=np.uint16);\n",
    "  plain1l = plain0l ^ diff[0]; plain1r = plain0r ^ diff[1];\n",
    "  num_rand_samples = np.sum(Y==0);\n",
    "  plain1l[Y==0] = np.frombuffer(urandom(2*num_rand_samples),dtype=np.uint16);\n",
    "  plain1r[Y==0] = np.frombuffer(urandom(2*num_rand_samples),dtype=np.uint16);\n",
    "  ks = expand_key(keys, nr);\n",
    "  ctdata0l, ctdata0r = encrypt((plain0l, plain0r), ks);\n",
    "  ctdata1l, ctdata1r = encrypt((plain1l, plain1r), ks);\n",
    "  X = convert_to_binary([ctdata0l, ctdata0r, ctdata1l, ctdata1r]);\n",
    "  return(X,Y);\n",
    "\n",
    "#real differences data generator\n",
    "def real_differences_data(n, nr, diff=(0x0040,0)):\n",
    "  #generate labels\n",
    "  Y = np.frombuffer(urandom(n), dtype=np.uint8); Y = Y & 1;\n",
    "  #generate keys\n",
    "  keys = np.frombuffer(urandom(8*n),dtype=np.uint16).reshape(4,-1);\n",
    "  #generate plaintexts\n",
    "  plain0l = np.frombuffer(urandom(2*n),dtype=np.uint16);\n",
    "  plain0r = np.frombuffer(urandom(2*n),dtype=np.uint16);\n",
    "  #apply input difference\n",
    "  plain1l = plain0l ^ diff[0]; plain1r = plain0r ^ diff[1];\n",
    "  num_rand_samples = np.sum(Y==0);\n",
    "  #expand keys and encrypt\n",
    "  ks = expand_key(keys, nr);\n",
    "  ctdata0l, ctdata0r = encrypt((plain0l, plain0r), ks);\n",
    "  ctdata1l, ctdata1r = encrypt((plain1l, plain1r), ks);\n",
    "  #generate blinding values\n",
    "  k0 = np.frombuffer(urandom(2*num_rand_samples),dtype=np.uint16);\n",
    "  k1 = np.frombuffer(urandom(2*num_rand_samples),dtype=np.uint16);\n",
    "  #apply blinding to the samples labelled as random\n",
    "  ctdata0l[Y==0] = ctdata0l[Y==0] ^ k0; ctdata0r[Y==0] = ctdata0r[Y==0] ^ k1;\n",
    "  ctdata1l[Y==0] = ctdata1l[Y==0] ^ k0; ctdata1r[Y==0] = ctdata1r[Y==0] ^ k1;\n",
    "  #convert to input data for neural networks\n",
    "  X = convert_to_binary([ctdata0l, ctdata0r, ctdata1l, ctdata1r]);\n",
    "  return(X,Y);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFRQpbmPq2Gd"
   },
   "source": [
    "# Evaluate the results #\n",
    "Taken from https://github.com/agohr/deep_speck/blob/master/eval.py and slightly adapted for evaluating the results of an autoencoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "3JUEUGNtKmM_"
   },
   "outputs": [],
   "source": [
    "def evaluate(net,X,Y):\n",
    "    \n",
    "    Z = net.predict(X,batch_size=5000).flatten();\n",
    "    Zbin = (Z > 0.5);\n",
    "\n",
    "    #Compute the acc, tpr, tnr\n",
    "    n = len(Z); \n",
    "    n0 = np.sum(Y==0); \n",
    "    n1 = np.sum(Y==1);\n",
    "    \n",
    "    acc = np.sum(Zbin == Y.flatten()) / n;\n",
    "    tpr = np.sum(Zbin[Y.flatten()==1]) / n1;\n",
    "    tnr = np.sum(Zbin[Y.flatten()==0] == 0) / n0;\n",
    "\n",
    "    return(acc, tpr, tnr);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wWNF6zOVq-tP"
   },
   "source": [
    "# Conduct multiple evaluations #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "bOxHHI6UKnpf"
   },
   "outputs": [],
   "source": [
    "def multiple_evaluations(model, repetitions, num_rounds):\n",
    " \n",
    "  #The accs, tprs, tnrs for all evaluation repetition\n",
    "  accs = [];\n",
    "  tprs = [];\n",
    "  tnrs = [];\n",
    "    \n",
    "  #Evaluate multiple times and average the results \n",
    "  for i in range(0, repetitions):\n",
    "    X_eval, Y_eval = make_train_data(10**6, num_rounds);\n",
    "\n",
    "    (acc, tpr, tnr) = evaluate(model, X_eval, X_eval);\n",
    "    accs.append(acc);\n",
    "    tprs.append(tpr);\n",
    "    tnrs.append(tnr);\n",
    "\n",
    "  print(\"Acc: \" + str(np.mean(accs)) + str(\" +- \") + str(np.std(accs)) + str(\"\\t\") + \n",
    "        \"Tpr:\" + str(np.mean(tprs)) + str(\" +- \") + str(np.std(tprs)) + str(\"\\t\") +\n",
    "        \"Tnr:\" + str(np.mean(tnrs)) + str(\" +- \") + str(np.std(tnrs)) + str(\"\\t\"));\n",
    "        \n",
    "  return(np.mean(accs), np.mean(tprs), np.mean(tnrs));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "327WPvIgKfpy"
   },
   "source": [
    "# Building the Autoencoder #\n",
    "The implementation for all three versions is provided below (already unfolded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ACV-2KFWiQ8n"
   },
   "outputs": [],
   "source": [
    "#The encoder\n",
    "def encode(input):\n",
    "\n",
    "  x = Reshape((4, 16))(input);\n",
    "  x = Permute((2,1))(x);\n",
    "\n",
    "  #Block 1\n",
    "  x = Conv1D(32, 3, padding='same')(x)\n",
    "  x = BatchNormalization()(x);\n",
    "  x = Activation('relu')(x);\n",
    "  x = MaxPooling1D(2, padding='same')(x)\n",
    "\n",
    "  #Block 2\n",
    "  #x = Conv1D(32, 3, padding='same')(x)\n",
    "  #x = BatchNormalization()(x);\n",
    "  #x = Activation('relu')(x);\n",
    "  #x = MaxPooling1D(2, padding='same')(x)\n",
    "    \n",
    "  #Block 3  \n",
    "  #x = Conv1D(32, 3, padding='same')(x)\n",
    "  #x = BatchNormalization()(x);\n",
    "  #x = Activation('relu')(x);\n",
    "  #x = MaxPooling1D(2, padding='same')(x)\n",
    "\n",
    "  encoded = x;\n",
    "    \n",
    "  return encoded;\n",
    "\n",
    "\n",
    "#The decoder\n",
    "def decode(encoded):\n",
    "  \n",
    "  #Block 1 \n",
    "  x = Conv1D(32, 3, padding='same')(encoded)\n",
    "  x = BatchNormalization()(x);\n",
    "  x = Activation('relu')(x);\n",
    "  x = UpSampling1D(2)(x)\n",
    "\n",
    "  #Block 2  \n",
    "  #x = Conv1D(32, 3, padding='same')(x)\n",
    "  #x = BatchNormalization()(x);\n",
    "  #x = Activation('relu')(x);\n",
    "  #x = UpSampling1D(2)(x)\n",
    "\n",
    "  #Block 3\n",
    "  #x = Conv1D(32, 3, padding='same')(x)\n",
    "  #x = BatchNormalization()(x);\n",
    "  #x = Activation('relu')(x);\n",
    "  #x = UpSampling1D(2)(x)\n",
    "\n",
    " \n",
    "  x = Conv1D(4, 3, activation='sigmoid', padding='same')(x)\n",
    "  x = Permute((2,1))(x);\n",
    "  decoded = Reshape((64,1))(x);\n",
    "\n",
    "  return decoded;\n",
    "\n",
    "\n",
    "#Using both the encoder and decoder to construct the autoencoder\n",
    "def build_autoencoder():\n",
    "    \n",
    "  inp = Input(shape=(64,));\n",
    "\n",
    "  encoded= encode(inp);\n",
    "  decoded = decode(encoded);\n",
    "\n",
    "  autoencoder = Model(inp, decoded);\n",
    "\n",
    "  autoencoder.compile(\n",
    "          optimizer='adam',\n",
    "          loss='binary_crossentropy',\n",
    "          metrics=['acc'])\n",
    "\n",
    "  return autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jnsKYtOcrXOJ"
   },
   "source": [
    "For training the autoencoder \\\n",
    "Taken from https://github.com/agohr/deep_speck/blob/master/train_nets.py and slightly adapted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "iTgp2ALnmHfr"
   },
   "outputs": [],
   "source": [
    "#Batch size\n",
    "bs=5000;\n",
    "\n",
    "def cyclic_lr(num_epochs, high_lr, low_lr):\n",
    "  res = lambda i: low_lr + ((num_epochs-1) - i % num_epochs)/(num_epochs-1) * (high_lr - low_lr);\n",
    "  return(res);\n",
    "\n",
    "def train_autoenc(model, num_epochs, num_rounds, X_train, Y_train, X_eval, Y_eval):\n",
    "    \n",
    "    stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_acc', patience=3, restore_best_weights= True);\n",
    "    lr = LearningRateScheduler(cyclic_lr(10,0.002, 0.0001));\n",
    "    \n",
    "    model.fit(X_train, Y_train, batch_size= bs, epochs=num_epochs,validation_data=(X_eval, Y_eval), callbacks=[lr, stop_early])\n",
    "    \n",
    "    return model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VkgGXWtpKfp0"
   },
   "source": [
    "# Repeat: Train the autoencoder and evaluate the results #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "QRAXF9ar361h"
   },
   "outputs": [],
   "source": [
    "def repeat_experiment(repetitions, num_rounds):\n",
    " \n",
    "  #Store the accs, tprs, tnrs for all experimenent repetitons\n",
    "  accs = [];\n",
    "  tprs = [];\n",
    "  tnrs = [];\n",
    "    \n",
    "  #Repeat the experiment multiple times\n",
    "  for i in range(0, repetitions):\n",
    "    \n",
    "    X_train, Y_train = make_train_data(10**7, num_rounds);\n",
    "    X_eval, Y_eval = make_train_data(10**6, num_rounds);\n",
    "    \n",
    "    initial_model = build_autoencoder();\n",
    "    #Set Y_train to X_train and Y_eval to X_eval\n",
    "    trained_model= train_autoenc(initial_model, 30, num_rounds, X_train, X_train, X_eval, X_eval);\n",
    "\n",
    "    (acc, tpr, tnr) = multiple_evaluations(trained_model,5,num_rounds);\n",
    "    accs.append(acc);\n",
    "    tprs.append(tpr);\n",
    "    tnrs.append(tnr);\n",
    " \n",
    "  print(\"\\n\") \n",
    "  print(\"Acc: \" + str(np.mean(accs)) + str(\" +- \") + str(np.std(accs)) + str(\"\\t\") + \n",
    "        \"Tpr:\" + str(np.mean(tprs)) + str(\" +- \") + str(np.std(tprs)) + str(\"\\t\") +\n",
    "        \"Tnr:\" + str(np.mean(tnrs)) + str(\" +- \") + str(np.std(tnrs)) + str(\"\\t\"));\n",
    "        \n",
    "  return(np.mean(accs), np.mean(tprs), np.mean(tnrs));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the experiment #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "fbsCeFZ6_HPr",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "2000/2000 [==============================] - 49s 8ms/step - loss: 0.1271 - acc: 0.9467 - val_loss: 0.0029 - val_acc: 0.9994\n",
      "Epoch 2/30\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0021 - acc: 0.9995 - val_loss: 0.0015 - val_acc: 0.9995\n",
      "Epoch 3/30\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0012 - acc: 0.9995 - val_loss: 0.0014 - val_acc: 0.9995\n",
      "Epoch 4/30\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 9.5792e-04 - acc: 0.9996 - val_loss: 9.6071e-04 - val_acc: 0.9996\n",
      "Epoch 5/30\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 8.6802e-04 - acc: 0.9996 - val_loss: 0.0010 - val_acc: 0.9995\n",
      "Epoch 6/30\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 8.2468e-04 - acc: 0.9996 - val_loss: 9.1428e-04 - val_acc: 0.9996\n",
      "Epoch 7/30\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 7.9684e-04 - acc: 0.9996 - val_loss: 8.9133e-04 - val_acc: 0.9996\n",
      "Epoch 8/30\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 7.7398e-04 - acc: 0.9996 - val_loss: 8.1484e-04 - val_acc: 0.9996\n",
      "Epoch 9/30\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 7.5186e-04 - acc: 0.9996 - val_loss: 8.1252e-04 - val_acc: 0.9996\n",
      "Epoch 10/30\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 7.3649e-04 - acc: 0.9996 - val_loss: 7.5503e-04 - val_acc: 0.9996\n",
      "Epoch 11/30\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 8.7985e-04 - acc: 0.9996 - val_loss: 0.0011 - val_acc: 0.9995\n",
      "Epoch 12/30\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 8.1829e-04 - acc: 0.9996 - val_loss: 8.6720e-04 - val_acc: 0.9996\n",
      "Epoch 13/30\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 8.0306e-04 - acc: 0.9996 - val_loss: 7.9979e-04 - val_acc: 0.9996\n",
      "Acc: 0.999619584375 +- 3.2474990377463627e-06\tTpr:0.9996755278162587 +- 3.5584676565424957e-06\tTnr:0.9995636422120375 +- 3.5414190443510174e-06\t\n",
      "Epoch 1/30\n",
      "2000/2000 [==============================] - 17s 8ms/step - loss: 0.1238 - acc: 0.9491 - val_loss: 0.0031 - val_acc: 0.9993\n",
      "Epoch 2/30\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0021 - acc: 0.9995 - val_loss: 0.0015 - val_acc: 0.9995\n",
      "Epoch 3/30\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0012 - acc: 0.9995 - val_loss: 0.0014 - val_acc: 0.9995\n",
      "Epoch 4/30\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 9.5492e-04 - acc: 0.9996 - val_loss: 0.0011 - val_acc: 0.9995\n",
      "Epoch 5/30\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 8.6323e-04 - acc: 0.9996 - val_loss: 8.5667e-04 - val_acc: 0.9996\n",
      "Epoch 6/30\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 8.1724e-04 - acc: 0.9996 - val_loss: 8.5751e-04 - val_acc: 0.9996\n",
      "Epoch 7/30\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 7.9410e-04 - acc: 0.9996 - val_loss: 8.0946e-04 - val_acc: 0.9996\n",
      "Epoch 8/30\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 7.6955e-04 - acc: 0.9996 - val_loss: 8.0200e-04 - val_acc: 0.9996\n",
      "Epoch 9/30\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 7.4857e-04 - acc: 0.9996 - val_loss: 8.4285e-04 - val_acc: 0.9996\n",
      "Epoch 10/30\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 7.3457e-04 - acc: 0.9996 - val_loss: 7.3619e-04 - val_acc: 0.9996\n",
      "Epoch 11/30\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 8.6939e-04 - acc: 0.9996 - val_loss: 8.9834e-04 - val_acc: 0.9996\n",
      "Epoch 12/30\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 8.1221e-04 - acc: 0.9996 - val_loss: 9.5901e-04 - val_acc: 0.9995\n",
      "Epoch 13/30\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 7.9437e-04 - acc: 0.9996 - val_loss: 7.8892e-04 - val_acc: 0.9996\n",
      "Acc: 0.9996205874999999 +- 1.2355650908533983e-06\tTpr:0.9995661957198756 +- 1.1267948349482246e-06\tTnr:0.9996749751145639 +- 2.0472899646886826e-06\t\n",
      "\n",
      "\n",
      "Acc: 0.9996200859375 +- 5.015624999771262e-07\tTpr:0.9996208617680671 +- 5.466604819154286e-05\tTnr:0.9996193086633007 +- 5.566645126320324e-05\t\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9996200859375, 0.9996208617680671, 0.9996193086633007)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#num_rounds = 5, 6, 7, 8 with an autoencoder with 1/2/3 blocks (need to un/comment the blocks in the autoencoder implementation - un/comment both the block from the encoder and its conterpart from the decoder so that the ecoder and decoder will have the same number of blocks)\n",
    "#num_repetitions = 5\n",
    "\n",
    "repeat_experiment(repetitions = 2, num_rounds =5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ----------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Kl-osRns7-y"
   },
   "source": [
    "# Steps for training with preprocessed input  #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rtxa38OO_HPw"
   },
   "source": [
    "# 1. Train the autoencoder of choice # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "AxN5Uy_y_HPw",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "2000/2000 [==============================] - 17s 8ms/step - loss: 0.1275 - acc: 0.9473 - val_loss: 0.0032 - val_acc: 0.9993\n",
      "Epoch 2/30\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0022 - acc: 0.9995 - val_loss: 0.0019 - val_acc: 0.9994\n",
      "Epoch 3/30\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0012 - acc: 0.9995 - val_loss: 0.0014 - val_acc: 0.9995\n",
      "Epoch 4/30\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 9.6302e-04 - acc: 0.9996 - val_loss: 0.0011 - val_acc: 0.9995\n",
      "Epoch 5/30\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 8.6804e-04 - acc: 0.9996 - val_loss: 0.0012 - val_acc: 0.9995\n",
      "Epoch 6/30\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 8.2239e-04 - acc: 0.9996 - val_loss: 9.2003e-04 - val_acc: 0.9996\n",
      "Epoch 7/30\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 7.9309e-04 - acc: 0.9996 - val_loss: 7.9617e-04 - val_acc: 0.9996\n",
      "Epoch 8/30\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 7.7099e-04 - acc: 0.9996 - val_loss: 8.0759e-04 - val_acc: 0.9996\n",
      "Epoch 9/30\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 7.5148e-04 - acc: 0.9996 - val_loss: 7.6309e-04 - val_acc: 0.9996\n",
      "Epoch 10/30\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 7.3947e-04 - acc: 0.9996 - val_loss: 7.4925e-04 - val_acc: 0.9996\n",
      "Epoch 11/30\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 8.7976e-04 - acc: 0.9996 - val_loss: 0.0012 - val_acc: 0.9995\n",
      "Epoch 12/30\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 8.1995e-04 - acc: 0.9996 - val_loss: 8.7536e-04 - val_acc: 0.9996\n",
      "Epoch 13/30\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 8.0557e-04 - acc: 0.9996 - val_loss: 0.0011 - val_acc: 0.9995\n"
     ]
    }
   ],
   "source": [
    "#Specify the number of rounds for which the autoencoder should be trained\n",
    "num_rounds = 5;\n",
    "\n",
    "X_train, Y_train = make_train_data(10**7, num_rounds);\n",
    "X_eval, Y_eval = make_train_data(10**6, num_rounds);\n",
    "    \n",
    "initial_model = build_autoencoder();\n",
    "\n",
    "#Set Y_train to X_train and Y_eval to X_eval\n",
    "trained_model= train_autoenc(initial_model, 30, num_rounds, X_train, X_train, X_eval, X_eval);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate an instance and predict \n",
    "X, _ = make_train_data(1, num_rounds)\n",
    "X_pred = trained_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At pozition: 0\t\tTrue value: 1\t\tPredicted value: 1.0\n",
      "At pozition: 1\t\tTrue value: 1\t\tPredicted value: 1.0\n",
      "At pozition: 2\t\tTrue value: 0\t\tPredicted value: 1.6348731e-16\n",
      "At pozition: 3\t\tTrue value: 1\t\tPredicted value: 1.0\n",
      "At pozition: 4\t\tTrue value: 1\t\tPredicted value: 0.9999999\n",
      "At pozition: 5\t\tTrue value: 0\t\tPredicted value: 8.5918295e-12\n",
      "At pozition: 6\t\tTrue value: 1\t\tPredicted value: 1.0\n",
      "At pozition: 7\t\tTrue value: 0\t\tPredicted value: 9.8976045e-09\n",
      "At pozition: 8\t\tTrue value: 1\t\tPredicted value: 1.0\n",
      "At pozition: 9\t\tTrue value: 0\t\tPredicted value: 4.391558e-09\n",
      "At pozition: 10\t\tTrue value: 0\t\tPredicted value: 2.2506596e-20\n",
      "At pozition: 11\t\tTrue value: 1\t\tPredicted value: 1.0\n",
      "At pozition: 12\t\tTrue value: 1\t\tPredicted value: 1.0\n",
      "At pozition: 13\t\tTrue value: 0\t\tPredicted value: 7.566932e-09\n",
      "At pozition: 14\t\tTrue value: 0\t\tPredicted value: 8.7065777e-13\n",
      "At pozition: 15\t\tTrue value: 0\t\tPredicted value: 1.1346213e-11\n",
      "At pozition: 16\t\tTrue value: 0\t\tPredicted value: 1.8506775e-21\n",
      "At pozition: 17\t\tTrue value: 0\t\tPredicted value: 2.9077648e-07\n",
      "At pozition: 18\t\tTrue value: 1\t\tPredicted value: 1.0\n",
      "At pozition: 19\t\tTrue value: 0\t\tPredicted value: 5.425201e-07\n",
      "At pozition: 20\t\tTrue value: 1\t\tPredicted value: 0.99999905\n",
      "At pozition: 21\t\tTrue value: 1\t\tPredicted value: 1.0\n",
      "At pozition: 22\t\tTrue value: 1\t\tPredicted value: 0.99701667\n",
      "At pozition: 23\t\tTrue value: 0\t\tPredicted value: 1.2056445e-05\n",
      "At pozition: 24\t\tTrue value: 1\t\tPredicted value: 0.9999858\n",
      "At pozition: 25\t\tTrue value: 0\t\tPredicted value: 2.2500359e-10\n",
      "At pozition: 26\t\tTrue value: 1\t\tPredicted value: 0.9999999\n",
      "At pozition: 27\t\tTrue value: 1\t\tPredicted value: 1.0\n",
      "At pozition: 28\t\tTrue value: 1\t\tPredicted value: 1.0\n",
      "At pozition: 29\t\tTrue value: 0\t\tPredicted value: 1.2032609e-12\n",
      "At pozition: 30\t\tTrue value: 0\t\tPredicted value: 6.0510276e-15\n",
      "At pozition: 31\t\tTrue value: 1\t\tPredicted value: 1.0\n",
      "At pozition: 32\t\tTrue value: 1\t\tPredicted value: 1.0\n",
      "At pozition: 33\t\tTrue value: 1\t\tPredicted value: 1.0\n",
      "At pozition: 34\t\tTrue value: 0\t\tPredicted value: 6.587946e-13\n",
      "At pozition: 35\t\tTrue value: 1\t\tPredicted value: 1.0\n",
      "At pozition: 36\t\tTrue value: 1\t\tPredicted value: 1.0\n",
      "At pozition: 37\t\tTrue value: 0\t\tPredicted value: 9.450567e-15\n",
      "At pozition: 38\t\tTrue value: 0\t\tPredicted value: 8.052865e-17\n",
      "At pozition: 39\t\tTrue value: 0\t\tPredicted value: 8.9650976e-10\n",
      "At pozition: 40\t\tTrue value: 1\t\tPredicted value: 1.0\n",
      "At pozition: 41\t\tTrue value: 1\t\tPredicted value: 1.0\n",
      "At pozition: 42\t\tTrue value: 1\t\tPredicted value: 1.0\n",
      "At pozition: 43\t\tTrue value: 1\t\tPredicted value: 1.0\n",
      "At pozition: 44\t\tTrue value: 1\t\tPredicted value: 1.0\n",
      "At pozition: 45\t\tTrue value: 1\t\tPredicted value: 1.0\n",
      "At pozition: 46\t\tTrue value: 0\t\tPredicted value: 3.950755e-12\n",
      "At pozition: 47\t\tTrue value: 0\t\tPredicted value: 1.35172635e-14\n",
      "At pozition: 48\t\tTrue value: 1\t\tPredicted value: 1.0\n",
      "At pozition: 49\t\tTrue value: 1\t\tPredicted value: 1.0\n",
      "At pozition: 50\t\tTrue value: 0\t\tPredicted value: 4.4465542e-09\n",
      "At pozition: 51\t\tTrue value: 1\t\tPredicted value: 1.0\n",
      "At pozition: 52\t\tTrue value: 1\t\tPredicted value: 1.0\n",
      "At pozition: 53\t\tTrue value: 1\t\tPredicted value: 1.0\n",
      "At pozition: 54\t\tTrue value: 0\t\tPredicted value: 1.4418737e-12\n",
      "At pozition: 55\t\tTrue value: 0\t\tPredicted value: 1.3533277e-15\n",
      "At pozition: 56\t\tTrue value: 1\t\tPredicted value: 1.0\n",
      "At pozition: 57\t\tTrue value: 1\t\tPredicted value: 1.0\n",
      "At pozition: 58\t\tTrue value: 1\t\tPredicted value: 1.0\n",
      "At pozition: 59\t\tTrue value: 1\t\tPredicted value: 1.0\n",
      "At pozition: 60\t\tTrue value: 0\t\tPredicted value: 7.66968e-12\n",
      "At pozition: 61\t\tTrue value: 1\t\tPredicted value: 1.0\n",
      "At pozition: 62\t\tTrue value: 1\t\tPredicted value: 1.0\n",
      "At pozition: 63\t\tTrue value: 1\t\tPredicted value: 0.9999999\n"
     ]
    }
   ],
   "source": [
    "#Print the result\n",
    "X_print= X[0];\n",
    "X_pred_print = list(X_pred[0].flatten());\n",
    "\n",
    "for i in range(64):\n",
    "  print(\"At pozition: \"+str(i) +\"\\t\\t\"+ \"True value: \" +str(X_print[i])+\"\\t\\t\" + \"Predicted value: \"+str(X_pred_print[i]));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JGyIf-waKfp1"
   },
   "source": [
    "# 2. Create an encoder model and set its weights to those of the encoder trained within the autoencoder from above #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "sb-dPP5bR6tp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_4\n",
      "reshape_6\n",
      "permute_6\n",
      "conv1d_9\n",
      "batch_normalization_6\n",
      "activation_6\n",
      "max_pooling1d_3\n"
     ]
    }
   ],
   "source": [
    "#Create the encoder model\n",
    "inpe = Input(shape=(64,));\n",
    "oute = encode(inpe); \n",
    "encoder_model = Model(inpe,oute)\n",
    "\n",
    "encoder_model.compile(\n",
    "          optimizer='adam',\n",
    "          loss='binary_crossentropy',\n",
    "          metrics=['acc']);\n",
    "\n",
    "#Set the weights to those of the pretrained encoder (from within the above-trained autoencoder)\n",
    "for l1,l2 in zip(encoder_model.layers,trained_model.layers):\n",
    "    l1.set_weights(l2.get_weights())\n",
    "    print(l1.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WQjl7FN6Kfp2"
   },
   "source": [
    "# 3. Do not allow the weights of the encoder to change #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "coBFk-aUKfp2"
   },
   "outputs": [],
   "source": [
    "for layer in encoder_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M2L9OuWo_HP0"
   },
   "source": [
    "# 4. Add the preprocessing step to the (reduced/depth-1/10) distinguisher #\n",
    "#### The network of the reduced distinguisher is given below.  \n",
    "Taken from https://github.com/agohr/deep_speck/blob/master/train_nets.py and slightly adapted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "jCTV3H78_HP1"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense, Conv1D,Conv2D, Input, Reshape, Permute, Add, Flatten, BatchNormalization, Activation, MaxPooling1D, Concatenate,Dropout, AveragePooling1D, GlobalAveragePooling1D, GlobalMaxPooling1D, UpSampling1D\n",
    "from keras.regularizers import l2, l1, l1_l2\n",
    "\n",
    "\n",
    "def cyclic_lr(num_epochs, high_lr, low_lr):\n",
    "  res = lambda i: low_lr + ((num_epochs-1) - i % num_epochs)/(num_epochs-1) * (high_lr - low_lr);\n",
    "  return(res);\n",
    "\n",
    "#Batch size\n",
    "bs = 5000;\n",
    "\n",
    "\n",
    "def make_resnet( num_blocks=2, num_filters=32, num_outputs=1, d1=64, d2=64, word_size=16, ks=3,depth=5, reg_param=0.0001, final_activation='sigmoid'):\n",
    "\n",
    "  #Input and preprocessing layers\n",
    "  inp = Input(shape=(64,));\n",
    "\n",
    "  #Encode the input  \n",
    "  x = encoder_model.call(inp); \n",
    "\n",
    "  \n",
    "  #Please paste your network of choice within the dotted lines - here, the discovered reduced network is given\n",
    "  #Also, do not forget to set the input of your network to x (the encoded inputs)  \n",
    "  \n",
    "  #---------------------------------------------------  \n",
    "  #Block 1: 7 filters were pruned \n",
    "  conv1 = Conv1D(filters=25, kernel_size=1, padding='same')(x); #Also refered to as C1\n",
    "  conv1 = BatchNormalization()(conv1);\n",
    "  conv1 = Activation('relu')(conv1);\n",
    "\n",
    "  #Block 2-i where:\n",
    "  #From its first convolutional layer: 21 filters were pruned\n",
    "  conv2 = Conv1D(filters=11, kernel_size=3, padding='same')(conv1); #Also refered to as C2\n",
    "  conv2 = BatchNormalization()(conv2);\n",
    "  conv2 = Activation('relu')(conv2);\n",
    "\n",
    "  #From its second convolutional layer: 25 filters were pruned\n",
    "  conv3 = Conv1D(filters=7, kernel_size=3, padding='same')(conv2); #Also refered to as C3\n",
    "  conv3 = BatchNormalization()(conv3);\n",
    "  conv3 = Activation('relu')(conv3);\n",
    "\n",
    "  #The residual connection was removed \n",
    "    \n",
    "  flat = Flatten()(conv3);\n",
    "\n",
    "  #Block 3 where:\n",
    "  #From its first dense layer: 46 neurons were pruned   \n",
    "  dense1 = Dense(18)(flat); #Also refered to as D1\n",
    "  dense1 = BatchNormalization()(dense1);\n",
    "  dense1 = Activation('relu')(dense1);\n",
    "    \n",
    "  #From its second dense layer: 36 neurons were pruned  \n",
    "  dense2 = Dense(28)(dense1); #Also refered to as D2\n",
    "  dense2 = BatchNormalization()(dense2);\n",
    "  dense2 = Activation('relu')(dense2);\n",
    "\n",
    "  out = Dense(1, activation='sigmoid')(dense2);\n",
    "  #---------------------------------------------------\n",
    "    \n",
    "    \n",
    "  model = Model(inputs=inp, outputs=out);\n",
    "\n",
    "  return model;\n",
    "\n",
    "\n",
    "\n",
    "def model_builder(depth):\n",
    "\n",
    "  model = make_resnet(depth=depth);\n",
    "\n",
    "  model.compile(\n",
    "          optimizer='adam',\n",
    "          loss='binary_crossentropy',\n",
    "          metrics=['acc']);\n",
    "    \n",
    "  return model;\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "def train_speck_distinguisher(model, num_epochs, num_rounds, X_train, Y_train, X_eval, Y_eval):\n",
    "    \n",
    "    stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_acc', patience=3, restore_best_weights= True);\n",
    "    lr = LearningRateScheduler(cyclic_lr(10,0.002, 0.0001));\n",
    "    \n",
    "    model.fit(X_train, Y_train, batch_size= bs, epochs=num_epochs, validation_data=(X_eval, Y_eval), callbacks=[lr, stop_early])\n",
    "    \n",
    "    return model;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Run the experiment #\n",
    "You can take the network (without the preprocessing of the inputs) directly from https://github.com/agohr/deep_speck/blob/master/train_nets.py \n",
    "\\\n",
    "Change the depth to 10 or 1 to conduct the other experiments, or take the detpth-1/10 network from the end of this notebook.\\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Demo, first the reduced network is used as a classifier, and then the depth-10 network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "gQYhtpxT_HP1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "2000/2000 [==============================] - 49s 8ms/step - loss: 0.4815 - acc: 0.7639 - val_loss: 0.3548 - val_acc: 0.8531\n",
      "Epoch 2/30\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.3366 - acc: 0.8612 - val_loss: 0.3274 - val_acc: 0.8653\n",
      "Epoch 3/30\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.3193 - acc: 0.8694 - val_loss: 0.3172 - val_acc: 0.8713\n",
      "Epoch 4/30\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.3118 - acc: 0.8732 - val_loss: 0.3117 - val_acc: 0.8731\n",
      "Epoch 5/30\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.3074 - acc: 0.8751 - val_loss: 0.3074 - val_acc: 0.8752\n",
      "Epoch 6/30\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.3037 - acc: 0.8768 - val_loss: 0.3037 - val_acc: 0.8768\n",
      "Epoch 7/30\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.3010 - acc: 0.8780 - val_loss: 0.3010 - val_acc: 0.8779\n",
      "Epoch 8/30\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.2983 - acc: 0.8793 - val_loss: 0.2990 - val_acc: 0.8791\n",
      "Epoch 9/30\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.2964 - acc: 0.8804 - val_loss: 0.2964 - val_acc: 0.8807\n",
      "Epoch 10/30\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2957 - acc: 0.8811 - val_loss: 0.2954 - val_acc: 0.8814\n",
      "Epoch 11/30\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.2978 - acc: 0.8805 - val_loss: 0.3050 - val_acc: 0.8775\n",
      "Epoch 12/30\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.2932 - acc: 0.8834 - val_loss: 0.2927 - val_acc: 0.8839\n",
      "Epoch 13/30\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.2908 - acc: 0.8847 - val_loss: 0.2929 - val_acc: 0.8835\n",
      "Epoch 14/30\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.2891 - acc: 0.8856 - val_loss: 0.2905 - val_acc: 0.8852\n",
      "Epoch 15/30\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.2880 - acc: 0.8862 - val_loss: 0.2953 - val_acc: 0.8821\n",
      "Epoch 16/30\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.2873 - acc: 0.8864 - val_loss: 0.2881 - val_acc: 0.8861\n",
      "Epoch 17/30\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.2867 - acc: 0.8867 - val_loss: 0.2886 - val_acc: 0.8858\n",
      "Epoch 18/30\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.2857 - acc: 0.8872 - val_loss: 0.2867 - val_acc: 0.8868\n",
      "Epoch 19/30\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.2855 - acc: 0.8872 - val_loss: 0.2870 - val_acc: 0.8865\n",
      "Epoch 20/30\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.2849 - acc: 0.8874 - val_loss: 0.2848 - val_acc: 0.8876\n",
      "Epoch 21/30\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.2885 - acc: 0.8859 - val_loss: 0.3017 - val_acc: 0.8782\n",
      "Epoch 22/30\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2874 - acc: 0.8863 - val_loss: 0.2957 - val_acc: 0.8823\n",
      "Epoch 23/30\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.2868 - acc: 0.8867 - val_loss: 0.2907 - val_acc: 0.8848\n"
     ]
    }
   ],
   "source": [
    "#Here, the reduced network is used as a classifier. The results are given below. \n",
    "initial_model_reduced_network = model_builder(depth=1); \n",
    "trained_model_reduced_network= train_speck_distinguisher(initial_model_reduced_network, 30, num_rounds, X_train, Y_train, X_eval, Y_eval);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.887205 +- 8.399999999997299e-05\tTpr:0.8361174308641061 +- 5.45802513906013e-05\tTnr:0.9384257290957074 +- 2.000469678131722e-05\t\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.887205, 0.8361174308641061, 0.9384257290957074)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluate the results\n",
    "multiple_evaluations_model_with_preprocessing(model = trained_model_reduced_network, repetitions = 2, num_rounds = num_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "2000/2000 [==============================] - 73s 30ms/step - loss: 0.4710 - acc: 0.8031 - val_loss: 0.3084 - val_acc: 0.8844\n",
      "Epoch 2/30\n",
      "2000/2000 [==============================] - 60s 30ms/step - loss: 0.2860 - acc: 0.8935 - val_loss: 0.2905 - val_acc: 0.8915\n",
      "Epoch 3/30\n",
      "2000/2000 [==============================] - 60s 30ms/step - loss: 0.2670 - acc: 0.9013 - val_loss: 0.2628 - val_acc: 0.9032\n",
      "Epoch 4/30\n",
      "2000/2000 [==============================] - 60s 30ms/step - loss: 0.2552 - acc: 0.9051 - val_loss: 0.3152 - val_acc: 0.8787\n",
      "Epoch 5/30\n",
      "2000/2000 [==============================] - 60s 30ms/step - loss: 0.2519 - acc: 0.9054 - val_loss: 0.2507 - val_acc: 0.9060\n",
      "Epoch 6/30\n",
      "2000/2000 [==============================] - 60s 30ms/step - loss: 0.2394 - acc: 0.9097 - val_loss: 0.2826 - val_acc: 0.8894\n",
      "Epoch 7/30\n",
      "2000/2000 [==============================] - 60s 30ms/step - loss: 0.2360 - acc: 0.9103 - val_loss: 0.2363 - val_acc: 0.9099\n",
      "Epoch 8/30\n",
      "2000/2000 [==============================] - 60s 30ms/step - loss: 0.2334 - acc: 0.9107 - val_loss: 0.2341 - val_acc: 0.9105\n",
      "Epoch 9/30\n",
      "2000/2000 [==============================] - 60s 30ms/step - loss: 0.2318 - acc: 0.9108 - val_loss: 0.2332 - val_acc: 0.9106\n",
      "Epoch 10/30\n",
      "2000/2000 [==============================] - 60s 30ms/step - loss: 0.2298 - acc: 0.9114 - val_loss: 0.2304 - val_acc: 0.9113\n",
      "Epoch 11/30\n",
      "2000/2000 [==============================] - 60s 30ms/step - loss: 0.2571 - acc: 0.9005 - val_loss: 0.2460 - val_acc: 0.9079\n",
      "Epoch 12/30\n",
      "2000/2000 [==============================] - 61s 30ms/step - loss: 0.2398 - acc: 0.9098 - val_loss: 0.2507 - val_acc: 0.9050\n",
      "Epoch 13/30\n",
      "2000/2000 [==============================] - 61s 30ms/step - loss: 0.2381 - acc: 0.9100 - val_loss: 0.2402 - val_acc: 0.9093\n"
     ]
    }
   ],
   "source": [
    "#Here, the depth-10 network is used as a classifier. The results are given below. \n",
    "initial_model_depth10 = model_builder(depth=10); \n",
    "trained_model_depth10 = train_speck_distinguisher(initial_model_depth10, 30, num_rounds, X_train, Y_train, X_eval, Y_eval);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9108855 +- 3.3500000000019625e-05\tTpr:0.8742460440545509 +- 0.00013561803774508885\tTnr:0.9476719777844262 +- 0.00015304689820411221\t\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9108855, 0.8742460440545509, 0.9476719777844262)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluate the results\n",
    "multiple_evaluations_model_with_preprocessing(model = trained_model_depth10, repetitions = 2, num_rounds = num_rounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluate function for evaluating the model with the encoder as a preprocessor.\\\n",
    "Taken from https://github.com/agohr/deep_speck/blob/master/eval.py and slightly adapted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_with_preprocessing(net,X,Y):\n",
    "    \n",
    "    Z = net.predict(X,batch_size=10000).flatten();\n",
    "    Zbin = (Z > 0.5);\n",
    "    \n",
    "    #Compute the acc, tpr, tnr\n",
    "    n = len(Z); \n",
    "    n0 = np.sum(Y==0); \n",
    "    n1 = np.sum(Y==1);\n",
    "    \n",
    "    acc = np.sum(Zbin == Y) / n;\n",
    "    tpr = np.sum(Zbin[Y==1]) / n1;\n",
    "    tnr = np.sum(Zbin[Y==0] == 0) / n0;\n",
    "    \n",
    "    return(acc, tpr, tnr); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conduct multiple evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_evaluations_model_with_preprocessing(model, repetitions, num_rounds):\n",
    " \n",
    "  #The accs, tprs, tnrs for all evaluation repetition\n",
    "  accs = [];\n",
    "  tprs = [];\n",
    "  tnrs = [];\n",
    "    \n",
    "  #Evaluate multiple times and average the results \n",
    "  for i in range(0, repetitions):\n",
    "    X_eval, Y_eval = make_train_data(10**6, num_rounds);\n",
    "\n",
    "    (acc, tpr, tnr) = evaluate_model_with_preprocessing(model, X_eval, Y_eval);\n",
    "    accs.append(acc);\n",
    "    tprs.append(tpr);\n",
    "    tnrs.append(tnr);\n",
    "\n",
    "  print(\"Acc: \" + str(np.mean(accs)) + str(\" +- \") + str(np.std(accs)) + str(\"\\t\") + \n",
    "        \"Tpr:\" + str(np.mean(tprs)) + str(\" +- \") + str(np.std(tprs)) + str(\"\\t\") +\n",
    "        \"Tnr:\" + str(np.mean(tnrs)) + str(\" +- \") + str(np.std(tnrs)) + str(\"\\t\"));\n",
    "        \n",
    "  return(np.mean(accs), np.mean(tprs), np.mean(tnrs));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gohr's network for conducting the above experiment with the depth-1/10 distinguisher \\\n",
    "Taken from https://github.com/agohr/deep_speck/blob/master/train_nets.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  #Block 1\n",
    "  conv0 = Conv1D(num_filters, kernel_size=1, padding='same', kernel_regularizer=l2(reg_param))(x);\n",
    "  conv0 = BatchNormalization()(conv0);\n",
    "  conv0 = Activation('relu')(conv0);\n",
    "\n",
    "  #Blocks 2-i - residual blocks\n",
    "  shortcut = conv0;\n",
    "  for i in range(depth):\n",
    "    conv1 = Conv1D(num_filters, kernel_size=ks, padding='same', kernel_regularizer=l2(reg_param))(shortcut);\n",
    "    conv1 = BatchNormalization()(conv1);\n",
    "    conv1 = Activation('relu')(conv1);\n",
    "    \n",
    "    conv2 = Conv1D(num_filters, kernel_size=ks, padding='same',kernel_regularizer=l2(reg_param))(conv1);\n",
    "    conv2 = BatchNormalization()(conv2);\n",
    "    conv2 = Activation('relu')(conv2);\n",
    "    shortcut = Add()([shortcut, conv2]);\n",
    "    \n",
    "  #Block 3\n",
    "  flat1 = Flatten()(shortcut);\n",
    "    \n",
    "  dense1 = Dense(d1,kernel_regularizer=l2(reg_param))(flat1);\n",
    "  dense1 = BatchNormalization()(dense1);\n",
    "  dense1 = Activation('relu')(dense1);\n",
    "\n",
    "  dense2 = Dense(d2, kernel_regularizer=l2(reg_param))(dense1);\n",
    "  dense2 = BatchNormalization()(dense2);\n",
    "  dense2 = Activation('relu')(dense2);\n",
    "    \n",
    "  out = Dense(num_outputs, activation=final_activation, kernel_regularizer=l2(reg_param))(dense2);"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TheSpeckAttack_Train_Autoencoders_and_Distinguishers_with_Preprocessing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
