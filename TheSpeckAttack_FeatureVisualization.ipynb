{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b_NClEn2y-EJ"
   },
   "outputs": [],
   "source": [
    "!pip install lime\n",
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ypPZEY9BuckP"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import warnings\n",
    "import sklearn.datasets\n",
    "import sklearn.ensemble\n",
    "import numpy as np\n",
    "import lime.submodular_pick\n",
    "import lime.lime_tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YYrc0_7kKfpr"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense, Conv1D, Input, Reshape, Permute, Add, Flatten, BatchNormalization, Activation, MaxPooling1D, Concatenate,Dropout, AveragePooling1D, GlobalAveragePooling1D, GlobalMaxPooling1D, UpSampling1D\n",
    "from keras.regularizers import l2, l1, l1_l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3_DwsHjRy0x7"
   },
   "source": [
    "# The Speck cipher and data generation algorithms #\n",
    "Taken from https://github.com/agohr/deep_speck/blob/master/speck.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-As2P_AK_gEW"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from os import urandom\n",
    "\n",
    "def WORD_SIZE():\n",
    "    return(16);\n",
    "\n",
    "def ALPHA():\n",
    "    return(7);\n",
    "\n",
    "def BETA():\n",
    "    return(2);\n",
    "\n",
    "MASK_VAL = 2 ** WORD_SIZE() - 1;\n",
    "\n",
    "def shuffle_together(l):\n",
    "    state = np.random.get_state();\n",
    "    for x in l:\n",
    "        np.random.set_state(state);\n",
    "        np.random.shuffle(x);\n",
    "\n",
    "def rol(x,k):\n",
    "    return(((x << k) & MASK_VAL) | (x >> (WORD_SIZE() - k)));\n",
    "\n",
    "def ror(x,k):\n",
    "    return((x >> k) | ((x << (WORD_SIZE() - k)) & MASK_VAL));\n",
    "\n",
    "def enc_one_round(p, k):\n",
    "    c0, c1 = p[0], p[1];\n",
    "    c0 = ror(c0, ALPHA());\n",
    "    c0 = (c0 + c1) & MASK_VAL;\n",
    "    c0 = c0 ^ k;\n",
    "    c1 = rol(c1, BETA());\n",
    "    c1 = c1 ^ c0;\n",
    "    return(c0,c1);\n",
    "\n",
    "def dec_one_round(c,k):\n",
    "    c0, c1 = c[0], c[1];\n",
    "    c1 = c1 ^ c0;\n",
    "    c1 = ror(c1, BETA());\n",
    "    c0 = c0 ^ k;\n",
    "    c0 = (c0 - c1) & MASK_VAL;\n",
    "    c0 = rol(c0, ALPHA());\n",
    "    return(c0, c1);\n",
    "\n",
    "def expand_key(k, t):\n",
    "    ks = [0 for i in range(t)];\n",
    "    ks[0] = k[len(k)-1];\n",
    "    l = list(reversed(k[:len(k)-1]));\n",
    "    for i in range(t-1):\n",
    "        l[i%3], ks[i+1] = enc_one_round((l[i%3], ks[i]), i);\n",
    "    return(ks);\n",
    "\n",
    "def encrypt(p, ks):\n",
    "    x, y = p[0], p[1];\n",
    "    for k in ks:\n",
    "        x,y = enc_one_round((x,y), k);\n",
    "    return(x, y);\n",
    "\n",
    "def decrypt(c, ks):\n",
    "    x, y = c[0], c[1];\n",
    "    for k in reversed(ks):\n",
    "        x, y = dec_one_round((x,y), k);\n",
    "    return(x,y);\n",
    "\n",
    "def check_testvector():\n",
    "  key = (0x1918,0x1110,0x0908,0x0100)\n",
    "  pt = (0x6574, 0x694c)\n",
    "  ks = expand_key(key, 22)\n",
    "  ct = encrypt(pt, ks)\n",
    "  if (ct == (0xa868, 0x42f2)):\n",
    "    print(\"Testvector verified.\")\n",
    "    return(True);\n",
    "  else:\n",
    "    print(\"Testvector not verified.\")\n",
    "    return(False);\n",
    "\n",
    "#convert_to_binary takes as input an array of ciphertext pairs\n",
    "#where the first row of the array contains the lefthand side of the ciphertexts,\n",
    "#the second row contains the righthand side of the ciphertexts,\n",
    "#the third row contains the lefthand side of the second ciphertexts,\n",
    "#and so on\n",
    "#it returns an array of bit vectors containing the same data\n",
    "def convert_to_binary(arr):\n",
    "  X = np.zeros((4 * WORD_SIZE(),len(arr[0])),dtype=np.uint8);\n",
    "  for i in range(4 * WORD_SIZE()):\n",
    "    index = i // WORD_SIZE();\n",
    "    offset = WORD_SIZE() - (i % WORD_SIZE()) - 1;\n",
    "    X[i] = (arr[index] >> offset) & 1;\n",
    "  X = X.transpose();\n",
    "  return(X);\n",
    "\n",
    "#takes a text file that contains encrypted block0, block1, true diff prob, real or random\n",
    "#data samples are line separated, the above items whitespace-separated\n",
    "#returns train data, ground truth, optimal ddt prediction\n",
    "def readcsv(datei):\n",
    "    data = np.genfromtxt(datei, delimiter=' ', converters={x: lambda s: int(s,16) for x in range(2)});\n",
    "    X0 = [data[i][0] for i in range(len(data))];\n",
    "    X1 = [data[i][1] for i in range(len(data))];\n",
    "    Y = [data[i][3] for i in range(len(data))];\n",
    "    Z = [data[i][2] for i in range(len(data))];\n",
    "    ct0a = [X0[i] >> 16 for i in range(len(data))];\n",
    "    ct1a = [X0[i] & MASK_VAL for i in range(len(data))];\n",
    "    ct0b = [X1[i] >> 16 for i in range(len(data))];\n",
    "    ct1b = [X1[i] & MASK_VAL for i in range(len(data))];\n",
    "    ct0a = np.array(ct0a, dtype=np.uint16); ct1a = np.array(ct1a,dtype=np.uint16);\n",
    "    ct0b = np.array(ct0b, dtype=np.uint16); ct1b = np.array(ct1b, dtype=np.uint16);\n",
    "    \n",
    "    #X = [[X0[i] >> 16, X0[i] & 0xffff, X1[i] >> 16, X1[i] & 0xffff] for i in range(len(data))];\n",
    "    X = convert_to_binary([ct0a, ct1a, ct0b, ct1b]); \n",
    "    Y = np.array(Y, dtype=np.uint8); Z = np.array(Z);\n",
    "    return(X,Y,Z);\n",
    "\n",
    "#baseline training data generator\n",
    "def make_train_data(n, nr, diff=(0x0040,0)):\n",
    "  Y = np.frombuffer(urandom(n), dtype=np.uint8); Y = Y & 1;\n",
    "  keys = np.frombuffer(urandom(8*n),dtype=np.uint16).reshape(4,-1);\n",
    "  plain0l = np.frombuffer(urandom(2*n),dtype=np.uint16);\n",
    "  plain0r = np.frombuffer(urandom(2*n),dtype=np.uint16);\n",
    "  plain1l = plain0l ^ diff[0]; plain1r = plain0r ^ diff[1];\n",
    "  num_rand_samples = np.sum(Y==0);\n",
    "  plain1l[Y==0] = np.frombuffer(urandom(2*num_rand_samples),dtype=np.uint16);\n",
    "  plain1r[Y==0] = np.frombuffer(urandom(2*num_rand_samples),dtype=np.uint16);\n",
    "  ks = expand_key(keys, nr);\n",
    "  ctdata0l, ctdata0r = encrypt((plain0l, plain0r), ks);\n",
    "  ctdata1l, ctdata1r = encrypt((plain1l, plain1r), ks);\n",
    "  X = convert_to_binary([ctdata0l, ctdata0r, ctdata1l, ctdata1r]);\n",
    "  return(X,Y);\n",
    "\n",
    "#real differences data generator\n",
    "def real_differences_data(n, nr, diff=(0x0040,0)):\n",
    "  #generate labels\n",
    "  Y = np.frombuffer(urandom(n), dtype=np.uint8); Y = Y & 1;\n",
    "  #generate keys\n",
    "  keys = np.frombuffer(urandom(8*n),dtype=np.uint16).reshape(4,-1);\n",
    "  #generate plaintexts\n",
    "  plain0l = np.frombuffer(urandom(2*n),dtype=np.uint16);\n",
    "  plain0r = np.frombuffer(urandom(2*n),dtype=np.uint16);\n",
    "  #apply input difference\n",
    "  plain1l = plain0l ^ diff[0]; plain1r = plain0r ^ diff[1];\n",
    "  num_rand_samples = np.sum(Y==0);\n",
    "  #expand keys and encrypt\n",
    "  ks = expand_key(keys, nr);\n",
    "  ctdata0l, ctdata0r = encrypt((plain0l, plain0r), ks);\n",
    "  ctdata1l, ctdata1r = encrypt((plain1l, plain1r), ks);\n",
    "  #generate blinding values\n",
    "  k0 = np.frombuffer(urandom(2*num_rand_samples),dtype=np.uint16);\n",
    "  k1 = np.frombuffer(urandom(2*num_rand_samples),dtype=np.uint16);\n",
    "  #apply blinding to the samples labelled as random\n",
    "  ctdata0l[Y==0] = ctdata0l[Y==0] ^ k0; ctdata0r[Y==0] = ctdata0r[Y==0] ^ k1;\n",
    "  ctdata1l[Y==0] = ctdata1l[Y==0] ^ k0; ctdata1r[Y==0] = ctdata1r[Y==0] ^ k1;\n",
    "  #convert to input data for neural networks\n",
    "  X = convert_to_binary([ctdata0l, ctdata0r, ctdata1l, ctdata1r]);\n",
    "  return(X,Y);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VKhJndYPzDtf"
   },
   "source": [
    "# The depth-1/10 distinguisher implementation - Reduced version #\n",
    "Taken from https://github.com/agohr/deep_speck/blob/master/train_nets.py and slightly adapted for running multiple trials. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "STtCeSLx8iCt"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense, Conv1D,Conv2D, Input, Reshape, Permute, Add, Flatten, BatchNormalization, Activation, MaxPooling1D, Concatenate,Dropout, AveragePooling1D, GlobalAveragePooling1D, GlobalMaxPooling1D, UpSampling1D\n",
    "from keras.regularizers import l2, l1, l1_l2\n",
    "\n",
    "\n",
    "def cyclic_lr(num_epochs, high_lr, low_lr):\n",
    "  res = lambda i: low_lr + ((num_epochs-1) - i % num_epochs)/(num_epochs-1) * (high_lr - low_lr);\n",
    "  return(res);\n",
    "\n",
    "#Batch size\n",
    "bs = 5000;\n",
    "\n",
    "def make_resnet( num_blocks=2, num_filters=32, num_outputs=1, d1=64, d2=64, word_size=16, ks=3,depth=5, reg_param=0.0001, final_activation='sigmoid'):\n",
    "\n",
    "  \n",
    "  inp = Input(shape=(64,));\n",
    "  x = Reshape((4, 16))(inp);\n",
    "  x = Permute((2,1))(x);\n",
    "  \n",
    "  conv0 = Conv1D(25, kernel_size=1, padding='same')(x);\n",
    "  conv0 = BatchNormalization()(conv0);\n",
    "  conv0 = Activation('relu')(conv0);\n",
    "\n",
    "  conv1 = Conv1D(11, kernel_size=ks, padding='same')(conv0);\n",
    "  conv1 = BatchNormalization()(conv1);\n",
    "  conv1 = Activation('relu')(conv1);\n",
    "\n",
    "  conv2 = Conv1D(7, kernel_size=ks, padding='same')(conv1);\n",
    "  conv2 = BatchNormalization()(conv2);\n",
    "  conv2 = Activation('relu')(conv2);\n",
    "\n",
    "  flat = Flatten()(conv2);\n",
    "\n",
    "  dense1 = Dense(18)(flat);\n",
    "  dense1 = BatchNormalization()(dense1);\n",
    "  dense1 = Activation('relu')(dense1);\n",
    "    \n",
    "  dense2 = Dense(28)(dense1);\n",
    "  dense2 = BatchNormalization()(dense2);\n",
    "  dense2 = Activation('relu')(dense2);\n",
    "\n",
    "  out = Dense(1, activation='sigmoid')(dense2);\n",
    "    \n",
    "  model = Model(inputs=inp, outputs=out);\n",
    "\n",
    "  return model;\n",
    "\n",
    "\n",
    "\n",
    "def model_builder(depth=1):\n",
    "\n",
    "  model = make_resnet(depth=depth);\n",
    "\n",
    "  model.compile(\n",
    "          optimizer='adam',\n",
    "          loss='binary_crossentropy',\n",
    "          metrics=['acc']);\n",
    "    \n",
    "  return model;\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "def train_speck_distinguisher(model, num_epochs, num_rounds, X_train, Y_train, X_eval, Y_eval):\n",
    "    \n",
    "    stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_acc', patience=3, restore_best_weights= True);\n",
    "    lr = LearningRateScheduler(cyclic_lr(10,0.002, 0.0001));\n",
    "    \n",
    "    model.fit(X_train, Y_train, batch_size= bs, epochs=num_epochs,validation_data=(X_eval, Y_eval), callbacks=[lr, stop_early])\n",
    "    \n",
    "    return model;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ts3UqJ9qzllx"
   },
   "source": [
    "Generate names for the 64 bits of the ciphertext pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S6hRwg4VyXuC"
   },
   "outputs": [],
   "source": [
    "def generate_names():\n",
    "  \n",
    "  names =[];\n",
    "  for i in range(64):\n",
    "    names.append(\"B\"+str(i));\n",
    "\n",
    "  return names;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z9ZXAll8yXuC"
   },
   "outputs": [],
   "source": [
    "feature_names = generate_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zt3hr_YbyXuD"
   },
   "source": [
    "# Train distinguisher #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "aZHcTur789i0"
   },
   "outputs": [],
   "source": [
    "#Select the number of rounds\n",
    "num_rounds = 5; # 5, 6, 7, 8\n",
    "\n",
    "X_train, Y_train = make_train_data(10**7, num_rounds);\n",
    "X_eval, Y_eval = make_train_data(10**6, num_rounds);\n",
    "\n",
    "initial_model = model_builder(1);\n",
    "trained_model= train_speck_distinguisher(initial_model, 30, num_rounds, X_train, Y_train, X_eval, Y_eval);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rqqvc4Ikz2ko"
   },
   "source": [
    "# Find ciphertext pairs with best/worst prediction #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nyPAIY31yXuE"
   },
   "outputs": [],
   "source": [
    "def find_best_preds(trained_model, num_preds, num_rounds):\n",
    "\n",
    "    #Compute predictions\n",
    "    X_eval, Y_eval = make_train_data(10**6, num_rounds);\n",
    "    predictions= trained_model.predict(X_eval, batch_size=5000)\n",
    " \n",
    "    #Best predictions for class 0 (random difference) and class 1 (fixed difference)\n",
    "    stored_0 =[];\n",
    "    stored_1 =[];\n",
    "    \n",
    "    #Get num_preds best predictions \n",
    "    for i in range(10**6):\n",
    "\n",
    "        diff = abs(Y_eval[i] - predictions[i]);\n",
    "        \n",
    "        #Store the current ciphertext pair if its prediction is better than that of the last ciphertext pair\n",
    "        if Y_eval[i] ==1 and (len(stored_1)==0 or diff <= stored_1[len(stored_1)-1][1]):\n",
    "            stored_1.append((i, diff, Y_eval[i], predictions[i], X_eval[i]));\n",
    "            \n",
    "        if Y_eval[i] ==0 and (len(stored_0)==0 or diff <= stored_0[len(stored_0)-1][1]):\n",
    "            stored_0.append((i, diff, Y_eval[i], predictions[i], X_eval[i]));\n",
    "\n",
    "    #Return just num_preds ciphertext pairs with the best predictions        \n",
    "    return stored_1[-num_preds:], stored_0[-num_preds:];\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kDumbBAByXuE"
   },
   "outputs": [],
   "source": [
    "def find_worst_preds(trained_model, num_preds, num_rounds):\n",
    "\n",
    "    X_eval, Y_eval = make_train_data(10**6, num_rounds);\n",
    "    predictions= trained_model.predict(X_eval, batch_size=5000)\n",
    "\n",
    "    stored_0 =[];\n",
    "    stored_1 =[];\n",
    "    \n",
    "    for i in range(10**6):\n",
    "\n",
    "        diff = abs(Y_eval[i] - predictions[i]);\n",
    "\n",
    "        #Store the current ciphertext pair if its prediction is worse than that of the last ciphertext pair\n",
    "        if Y_eval[i] ==1 and (len(stored_1)==0 or diff >= stored_1[len(stored_1)-1][1]):\n",
    "            stored_1.append((i, diff, Y_eval[i], predictions[i], X_eval[i]));\n",
    "            \n",
    "        if Y_eval[i] ==0 and (len(stored_0)==0 or diff >= stored_0[len(stored_0)-1][1]):\n",
    "            stored_0.append((i, diff, Y_eval[i], predictions[i], X_eval[i]));\n",
    "\n",
    "    #Return just num_preds ciphertext pairs with the worst predictions \n",
    "    return stored_1[-num_preds:], stored_0[-num_preds:];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain the ciphertext pairs with the best predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xvzRGnffyXuE"
   },
   "outputs": [],
   "source": [
    "#Contain ciphertext pairs belonging to class 1 (fixed difference) and class 0 (random difference)\n",
    "c1, c0 = find_best_preds(trained_model, 5, 5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zK4mM1U1z-dR"
   },
   "source": [
    "# Instantiate the explainer #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-jZ523ViyXuF"
   },
   "outputs": [],
   "source": [
    "explainer = lime.lime_tabular.LimeTabularExplainer(X_train, class_names= ['Fixed difference'], feature_names=feature_names,discretize_continuous=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ykJy_Gp8yXuF"
   },
   "source": [
    "# Compute explanations for class 1 - fixed difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_yGB40XJyXuF"
   },
   "outputs": [],
   "source": [
    "#Choose for which of the above num_preds instances to generate an explanation  \n",
    "instance = 4;\n",
    "\n",
    "exp = explainer.explain_instance(c1[0][instance], trained_model.predict, num_features=64, num_samples=10**7, labels=[0])\n",
    "\n",
    "#Figure with explanations\n",
    "exp.show_in_notebook(show_table=True, show_all=True)\n",
    "fig = exp.as_pyplot_figure(label=0);\n",
    "fig.set_size_inches(10, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uPWJmJLCyXuj"
   },
   "source": [
    "# Compute explanations for class 0 - random difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HzCbZ2lyyXuj"
   },
   "outputs": [],
   "source": [
    "#Choose for which of the above num_preds instances to generate an explanation  \n",
    "instance = 4;\n",
    "\n",
    "exp = explainer.explain_instance(c0[0][instance], trained_model.predict, num_features=64, num_samples=10**7, labels=[0])\n",
    "\n",
    "#Figure with explanations\n",
    "exp.show_in_notebook(show_table=True, show_all=True)\n",
    "fig = exp.as_pyplot_figure(label=0);\n",
    "fig.set_size_inches(10, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FEts9lZ_yXyg"
   },
   "source": [
    "# Submodular Explainer #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qTiRBFBUyXyh"
   },
   "outputs": [],
   "source": [
    "num_rounds = 5; # 5, 6, 7, 8\n",
    "\n",
    "X_train, Y_train = make_train_data(10**7, num_rounds);\n",
    "X_eval, Y_eval = make_train_data(10**6, num_rounds);\n",
    "\n",
    "initial_model = model_builder(1);\n",
    "trained_model= train_speck_distinguisher(initial_model, 30, num_rounds, X_train, Y_train, X_eval, Y_eval);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BPkpz3W4yXyh"
   },
   "outputs": [],
   "source": [
    "#Instances are chosen\n",
    "sp_obj = submodular_pick.SubmodularPick(explainer, X_train, trained_model.predict, method='sample', num_features=64, num_exps_desired=5,  sample_size =5000) \n",
    "\n",
    "#Figures with explanations \n",
    "[exp.as_pyplot_figure(label=exp.available_labels()[0]).set_size_inches(10, 15) for exp in sp_obj.sp_explanations];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ahFpjvRVyXyj"
   },
   "outputs": [],
   "source": [
    "#Complete explanations \n",
    "[exp.show_in_notebook(show_table=True, show_all=True) for exp in sp_obj.sp_explanations];"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TheSpeckAttack_FeatureVisualization.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
